{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Неделя 3. Соревнование. Logistic Regression\n",
    "\n",
    "Продолжение решения. Начало в ноутбуке week3_peer.\n",
    "\n",
    "В этом задании вам нужно воспользоваться опытом предыдущих недель, чтобы побить бейзлайн в [соревновании по сентимент-анализу отзывов](https://www.kaggle.com/c/product-reviews-sentiment-analysis-light) на товары на Kaggle Inclass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import roc_curve, accuracy_score, roc_auc_score\n",
    "from nltk.corpus import stopwords\n",
    "from random import shuffle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8269"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seed = random.randint(0, 10000)\n",
    "seed = 8269\n",
    "seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 . take around 10,000 640x480 pictures .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i downloaded a trial version of computer assoc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the wrt54g plus the hga7t is a perfect solutio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i dont especially like how music files are uns...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i was using the cheapie pail ... and it worked...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  class\n",
       "0          2 . take around 10,000 640x480 pictures .      1\n",
       "1  i downloaded a trial version of computer assoc...      1\n",
       "2  the wrt54g plus the hga7t is a perfect solutio...      1\n",
       "3  i dont especially like how music files are uns...      0\n",
       "4  i was using the cheapie pail ... and it worked...      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\n",
    "    \"..\\..\\Data\\products_sentiment_train.tsv\",\n",
    "    \"\\t\",\n",
    "    names=[\"text\", \"class\"],\n",
    "    dtype={ \"text\": \"str\", \"class\": \"int\" })\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>so , why the small digital elph , rather than ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3/4 way through the first disk we played on it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>better for the zen micro is outlook compatibil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6 . play gameboy color games on it with goboy .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>likewise , i 've heard norton 2004 professiona...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text\n",
       "Id                                                   \n",
       "0   so , why the small digital elph , rather than ...\n",
       "1   3/4 way through the first disk we played on it...\n",
       "2   better for the zen micro is outlook compatibil...\n",
       "3     6 . play gameboy color games on it with goboy .\n",
       "4   likewise , i 've heard norton 2004 professiona..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv(\n",
    "    \"..\\..\\Data\\products_sentiment_test.tsv\",\n",
    "    \"\\t\",\n",
    "    index_col=\"Id\",\n",
    "    dtype={ \"text\": \"str\", \"Id\": \"int\" })\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = train_data[\"text\"].tolist()\n",
    "classes = train_data[\"class\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_columns = [\"Accuracy\", \"Accuracy_std\", \"ROC_AUC\", \"ROC_AUC_std\"]\n",
    "results = pd.DataFrame(columns=result_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model_template(\n",
    "    model_name,\n",
    "    model_pipe,\n",
    "    frame,\n",
    "    frame_columns,\n",
    "    score_texts,\n",
    "    score_classes,\n",
    "    print_results=True\n",
    "):\n",
    "    \"\"\" Функция принимает на вход модель, данные и фрейм с результатами, возвращает новый фрейм с обновленными результатами. \"\"\"\n",
    "    accuracy_scores = cross_val_score(\n",
    "        model_pipe,\n",
    "        score_texts,\n",
    "        score_classes,\n",
    "        scoring=\"accuracy\")\n",
    "    roc_auc_scores = cross_val_score(\n",
    "        model_pipe,\n",
    "        score_texts,\n",
    "        score_classes,\n",
    "        scoring=\"roc_auc\")\n",
    "    average_accuracy = np.average(accuracy_scores)\n",
    "    std_accuracy = np.std(accuracy_scores)\n",
    "    average_roc_auc = np.average(roc_auc_scores)\n",
    "    std_roc_auc = np.std(roc_auc_scores)\n",
    "    frame = frame.append(pd.DataFrame([\n",
    "        [average_accuracy, std_accuracy, average_roc_auc, std_roc_auc]\n",
    "    ], index=[model_name], columns=frame_columns))\n",
    "    if(print_results):\n",
    "        print (\"Accuracy:\\n\\tAverage: {0:.3f}\\n\\tStandard Deviation: {1:.3f}\".format(\n",
    "            average_accuracy,\n",
    "            std_accuracy))\n",
    "        print (\"ROC AUC:\\n\\tAverage: {0:.3f}\\n\\tStandard Deviation: {1:.3f}\".format(\n",
    "            np.average(roc_auc_scores),\n",
    "            np.std(roc_auc_scores)))\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline\n",
    "В этом ноутбуке исследуем Logistic Regression.\n",
    "В качестве baseline используем Logistic Regression, с настройками по-умолчанию и CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "\tAverage: 0.774\n",
      "\tStandard Deviation: 0.023\n",
      "ROC AUC:\n",
      "\tAverage: 0.832\n",
      "\tStandard Deviation: 0.020\n"
     ]
    }
   ],
   "source": [
    "count_logistic_pipe = Pipeline([\n",
    "    (\"vectorize\", CountVectorizer()),\n",
    "    (\"model\", LogisticRegression(random_state=seed))])\n",
    "results = score_model_template(\n",
    "    \"Count Logistic\",\n",
    "    count_logistic_pipe,\n",
    "    results,\n",
    "    result_columns,\n",
    "    texts,\n",
    "    classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data balancing\n",
    "Попробуем сбалансировать данные и посмотрим насколько изменение баланса в данных влияет на качество предсказаний. Исследуем два метода: Oversampling и Class Weights. Undersampling пробовать не будем, т.к. данных довольно мало."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling\n",
    "Разница в количестве примерова в классах (diff_size) - 548 примеров.\n",
    "Посмотрим насколько влияют oversampling меньшего класса, то числа близкого к 548."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_data(input_texts, input_classes, diff_size):\n",
    "    negative_texts, negative_classes = zip(*filter(lambda row: row[1] == 0, zip(input_texts, input_classes)))\n",
    "    negative_texts_list = []\n",
    "    random.seed(seed)\n",
    "    for i in range(0, diff_size):\n",
    "        negative_texts_list = negative_texts_list + [negative_texts[random.randint(0, len(negative_texts)- 1)]]\n",
    "        \n",
    "    balanced_texts = input_texts + negative_texts_list\n",
    "    balanced_classes = input_classes + ([0] * diff_size)\n",
    "    balanced_data = list(zip(balanced_texts, balanced_classes))\n",
    "    shuffle(balanced_data)\n",
    "    return zip(*balanced_data)\n",
    "\n",
    "def score_model_oversampling(\n",
    "    model_name,\n",
    "    model_pipe,\n",
    "    frame,\n",
    "    frame_columns,\n",
    "    print_results=True\n",
    "):\n",
    "    oversampled_texts, oversampled_classes = balance_data(texts, classes, 548)\n",
    "    return score_model_template(\n",
    "        model_name,\n",
    "        model_pipe,\n",
    "        frame,\n",
    "        frame_columns,\n",
    "        oversampled_texts,\n",
    "        oversampled_classes,\n",
    "        print_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "\tAverage: 0.818\n",
      "\tStandard Deviation: 0.011\n",
      "ROC AUC:\n",
      "\tAverage: 0.897\n",
      "\tStandard Deviation: 0.009\n"
     ]
    }
   ],
   "source": [
    "oversampling_results = results\n",
    "oversampling_results = score_model_oversampling(\n",
    "    \"Count Logistic oversampled\",\n",
    "    count_logistic_pipe,\n",
    "    oversampling_results,\n",
    "    result_columns\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что Oversampling довольно существенно улучшает качество предсказаний"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Weights\n",
    "Негативных отзывов в 1.7548 раз меньше, чем позитивных. Попоробуем задать негативному классу больший вес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Accuracy_std</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>ROC_AUC_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Count Logistic weighted 1.1548</th>\n",
       "      <td>0.775506</td>\n",
       "      <td>0.021571</td>\n",
       "      <td>0.831115</td>\n",
       "      <td>0.020682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count Logistic</th>\n",
       "      <td>0.774007</td>\n",
       "      <td>0.022582</td>\n",
       "      <td>0.831514</td>\n",
       "      <td>0.020428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count Logistic weighted 1.2548</th>\n",
       "      <td>0.772004</td>\n",
       "      <td>0.019382</td>\n",
       "      <td>0.830872</td>\n",
       "      <td>0.020799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count Logistic weighted 1.4548</th>\n",
       "      <td>0.769001</td>\n",
       "      <td>0.013607</td>\n",
       "      <td>0.830447</td>\n",
       "      <td>0.020816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count Logistic weighted 1.3548</th>\n",
       "      <td>0.768503</td>\n",
       "      <td>0.017110</td>\n",
       "      <td>0.830625</td>\n",
       "      <td>0.020742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count Logistic weighted 1.5548</th>\n",
       "      <td>0.766499</td>\n",
       "      <td>0.013558</td>\n",
       "      <td>0.830155</td>\n",
       "      <td>0.020939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count Logistic weighted 1.6547999999999998</th>\n",
       "      <td>0.761000</td>\n",
       "      <td>0.017751</td>\n",
       "      <td>0.829902</td>\n",
       "      <td>0.021028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count Logistic weighted 1.7548</th>\n",
       "      <td>0.758998</td>\n",
       "      <td>0.016736</td>\n",
       "      <td>0.829760</td>\n",
       "      <td>0.021066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count Logistic weighted 2.0548</th>\n",
       "      <td>0.757497</td>\n",
       "      <td>0.014864</td>\n",
       "      <td>0.829153</td>\n",
       "      <td>0.021231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count Logistic weighted 2.1548</th>\n",
       "      <td>0.757496</td>\n",
       "      <td>0.016948</td>\n",
       "      <td>0.828968</td>\n",
       "      <td>0.021239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count Logistic weighted 1.8548</th>\n",
       "      <td>0.756496</td>\n",
       "      <td>0.017888</td>\n",
       "      <td>0.829549</td>\n",
       "      <td>0.021124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count Logistic weighted 1.9548</th>\n",
       "      <td>0.755496</td>\n",
       "      <td>0.017410</td>\n",
       "      <td>0.829322</td>\n",
       "      <td>0.021178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count Logistic weighted 2.4547999999999996</th>\n",
       "      <td>0.754496</td>\n",
       "      <td>0.015805</td>\n",
       "      <td>0.828426</td>\n",
       "      <td>0.021218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count Logistic weighted 2.2548</th>\n",
       "      <td>0.753496</td>\n",
       "      <td>0.015558</td>\n",
       "      <td>0.828835</td>\n",
       "      <td>0.021195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count Logistic weighted 2.3548</th>\n",
       "      <td>0.753496</td>\n",
       "      <td>0.015377</td>\n",
       "      <td>0.828670</td>\n",
       "      <td>0.021210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count Logistic weighted 2.5548</th>\n",
       "      <td>0.751997</td>\n",
       "      <td>0.014653</td>\n",
       "      <td>0.828280</td>\n",
       "      <td>0.021184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count Logistic weighted 2.7548</th>\n",
       "      <td>0.751497</td>\n",
       "      <td>0.016029</td>\n",
       "      <td>0.828069</td>\n",
       "      <td>0.021262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count Logistic weighted 2.6548</th>\n",
       "      <td>0.751496</td>\n",
       "      <td>0.015806</td>\n",
       "      <td>0.828134</td>\n",
       "      <td>0.021246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count Logistic weighted 2.8548</th>\n",
       "      <td>0.750997</td>\n",
       "      <td>0.015340</td>\n",
       "      <td>0.828095</td>\n",
       "      <td>0.021211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count Logistic weighted 2.9547999999999996</th>\n",
       "      <td>0.749498</td>\n",
       "      <td>0.015666</td>\n",
       "      <td>0.828021</td>\n",
       "      <td>0.021262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Accuracy  Accuracy_std   ROC_AUC  \\\n",
       "Count Logistic weighted 1.1548              0.775506      0.021571  0.831115   \n",
       "Count Logistic                              0.774007      0.022582  0.831514   \n",
       "Count Logistic weighted 1.2548              0.772004      0.019382  0.830872   \n",
       "Count Logistic weighted 1.4548              0.769001      0.013607  0.830447   \n",
       "Count Logistic weighted 1.3548              0.768503      0.017110  0.830625   \n",
       "Count Logistic weighted 1.5548              0.766499      0.013558  0.830155   \n",
       "Count Logistic weighted 1.6547999999999998  0.761000      0.017751  0.829902   \n",
       "Count Logistic weighted 1.7548              0.758998      0.016736  0.829760   \n",
       "Count Logistic weighted 2.0548              0.757497      0.014864  0.829153   \n",
       "Count Logistic weighted 2.1548              0.757496      0.016948  0.828968   \n",
       "Count Logistic weighted 1.8548              0.756496      0.017888  0.829549   \n",
       "Count Logistic weighted 1.9548              0.755496      0.017410  0.829322   \n",
       "Count Logistic weighted 2.4547999999999996  0.754496      0.015805  0.828426   \n",
       "Count Logistic weighted 2.2548              0.753496      0.015558  0.828835   \n",
       "Count Logistic weighted 2.3548              0.753496      0.015377  0.828670   \n",
       "Count Logistic weighted 2.5548              0.751997      0.014653  0.828280   \n",
       "Count Logistic weighted 2.7548              0.751497      0.016029  0.828069   \n",
       "Count Logistic weighted 2.6548              0.751496      0.015806  0.828134   \n",
       "Count Logistic weighted 2.8548              0.750997      0.015340  0.828095   \n",
       "Count Logistic weighted 2.9547999999999996  0.749498      0.015666  0.828021   \n",
       "\n",
       "                                            ROC_AUC_std  \n",
       "Count Logistic weighted 1.1548                 0.020682  \n",
       "Count Logistic                                 0.020428  \n",
       "Count Logistic weighted 1.2548                 0.020799  \n",
       "Count Logistic weighted 1.4548                 0.020816  \n",
       "Count Logistic weighted 1.3548                 0.020742  \n",
       "Count Logistic weighted 1.5548                 0.020939  \n",
       "Count Logistic weighted 1.6547999999999998     0.021028  \n",
       "Count Logistic weighted 1.7548                 0.021066  \n",
       "Count Logistic weighted 2.0548                 0.021231  \n",
       "Count Logistic weighted 2.1548                 0.021239  \n",
       "Count Logistic weighted 1.8548                 0.021124  \n",
       "Count Logistic weighted 1.9548                 0.021178  \n",
       "Count Logistic weighted 2.4547999999999996     0.021218  \n",
       "Count Logistic weighted 2.2548                 0.021195  \n",
       "Count Logistic weighted 2.3548                 0.021210  \n",
       "Count Logistic weighted 2.5548                 0.021184  \n",
       "Count Logistic weighted 2.7548                 0.021262  \n",
       "Count Logistic weighted 2.6548                 0.021246  \n",
       "Count Logistic weighted 2.8548                 0.021211  \n",
       "Count Logistic weighted 2.9547999999999996     0.021262  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_results = results\n",
    "for weight_part in range(1, 20):\n",
    "    weight = 1.0548 + float(weight_part)/10\n",
    "    logistic_count_weights_pipe = Pipeline([\n",
    "        (\"vectorize\", CountVectorizer()),\n",
    "        (\"model\", LogisticRegression(\n",
    "            class_weight={\n",
    "                0: weight,\n",
    "                1: 1\n",
    "            }\n",
    "        ))])\n",
    "    weight_results = score_model_template(\n",
    "        \"Count Logistic weighted {0}\".format(weight),\n",
    "        logistic_count_weights_pipe,\n",
    "        weight_results,\n",
    "        result_columns,\n",
    "        texts,\n",
    "        classes,\n",
    "        False\n",
    "    )\n",
    "weight_results.sort_values(\"Accuracy\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь видно, что существенно увеличить качество модели с помощью class weights не удалось"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "\tAverage: 0.818\n",
      "\tStandard Deviation: 0.011\n",
      "ROC AUC:\n",
      "\tAverage: 0.897\n",
      "\tStandard Deviation: 0.009\n"
     ]
    }
   ],
   "source": [
    "count_logistic_pipe = Pipeline([\n",
    "    (\"vectorize\", CountVectorizer()),\n",
    "    (\"model\", LogisticRegression(random_state=seed))])\n",
    "results = score_model_oversampling(\n",
    "    \"Count Logistic\",\n",
    "    count_logistic_pipe,\n",
    "    results,\n",
    "    result_columns\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### English stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "\tAverage: 0.812\n",
      "\tStandard Deviation: 0.009\n",
      "ROC AUC:\n",
      "\tAverage: 0.891\n",
      "\tStandard Deviation: 0.006\n"
     ]
    }
   ],
   "source": [
    "english_stopwords = stopwords.words(\"english\")\n",
    "nltk_stopwords_count_logistic = Pipeline([\n",
    "    (\"vectorize\", CountVectorizer(stop_words=english_stopwords)),\n",
    "    (\"model\", LogisticRegression(random_state=seed))\n",
    "])\n",
    "results = score_model_oversampling(\n",
    "    \"Count NLTK English stopwords logistic\",\n",
    "    nltk_stopwords_count_logistic,\n",
    "    results,\n",
    "    result_columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "\tAverage: 0.804\n",
      "\tStandard Deviation: 0.010\n",
      "ROC AUC:\n",
      "\tAverage: 0.888\n",
      "\tStandard Deviation: 0.005\n"
     ]
    }
   ],
   "source": [
    "sklearn_stopwords_count_logistic = Pipeline([\n",
    "    (\"vectorize\", CountVectorizer(stop_words=\"english\")),\n",
    "    (\"model\", LogisticRegression(random_state=seed))\n",
    "])\n",
    "results = score_model_oversampling(\n",
    "    \"Count Sklearn English stopwords logistic\",\n",
    "    sklearn_stopwords_count_logistic,\n",
    "    results,\n",
    "    result_columns\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Accuracy_std</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>ROC_AUC_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Count Logistic</th>\n",
       "      <td>0.774007</td>\n",
       "      <td>0.022582</td>\n",
       "      <td>0.831514</td>\n",
       "      <td>0.020428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count Logistic</th>\n",
       "      <td>0.817895</td>\n",
       "      <td>0.010648</td>\n",
       "      <td>0.897232</td>\n",
       "      <td>0.009240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count NLTK English stopwords logistic</th>\n",
       "      <td>0.812407</td>\n",
       "      <td>0.008775</td>\n",
       "      <td>0.891127</td>\n",
       "      <td>0.005639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count Sklearn English stopwords logistic</th>\n",
       "      <td>0.804168</td>\n",
       "      <td>0.009856</td>\n",
       "      <td>0.887977</td>\n",
       "      <td>0.005197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count N-grams (1,2) logistic</th>\n",
       "      <td>0.830850</td>\n",
       "      <td>0.014552</td>\n",
       "      <td>0.917302</td>\n",
       "      <td>0.006241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count N-grams (1,3) logistic</th>\n",
       "      <td>0.834383</td>\n",
       "      <td>0.013282</td>\n",
       "      <td>0.921745</td>\n",
       "      <td>0.005949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count N-grams (1,4) logistic</th>\n",
       "      <td>0.835168</td>\n",
       "      <td>0.008305</td>\n",
       "      <td>0.922530</td>\n",
       "      <td>0.006164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count N-grams (1,5) logistic</th>\n",
       "      <td>0.836348</td>\n",
       "      <td>0.009070</td>\n",
       "      <td>0.922453</td>\n",
       "      <td>0.006407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count N-grams (1,6) logistic</th>\n",
       "      <td>0.835562</td>\n",
       "      <td>0.006268</td>\n",
       "      <td>0.922177</td>\n",
       "      <td>0.006631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count N-grams (1,7) logistic</th>\n",
       "      <td>0.834383</td>\n",
       "      <td>0.006013</td>\n",
       "      <td>0.921943</td>\n",
       "      <td>0.006697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count N-grams (1,8) logistic</th>\n",
       "      <td>0.832813</td>\n",
       "      <td>0.006659</td>\n",
       "      <td>0.921537</td>\n",
       "      <td>0.006950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count N-grams (1,9) logistic</th>\n",
       "      <td>0.831635</td>\n",
       "      <td>0.004902</td>\n",
       "      <td>0.921291</td>\n",
       "      <td>0.007067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count N-grams (1,10) logistic</th>\n",
       "      <td>0.831243</td>\n",
       "      <td>0.005457</td>\n",
       "      <td>0.921062</td>\n",
       "      <td>0.007077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count N-grams (1,11) logistic</th>\n",
       "      <td>0.831636</td>\n",
       "      <td>0.006566</td>\n",
       "      <td>0.920707</td>\n",
       "      <td>0.007235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count N-grams (1,12) logistic</th>\n",
       "      <td>0.833207</td>\n",
       "      <td>0.006851</td>\n",
       "      <td>0.920408</td>\n",
       "      <td>0.007238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count N-grams (1,13) logistic</th>\n",
       "      <td>0.832814</td>\n",
       "      <td>0.006567</td>\n",
       "      <td>0.920240</td>\n",
       "      <td>0.007248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count N-grams (1,14) logistic</th>\n",
       "      <td>0.832813</td>\n",
       "      <td>0.005768</td>\n",
       "      <td>0.920085</td>\n",
       "      <td>0.007259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count N-grams (1,15) logistic</th>\n",
       "      <td>0.831241</td>\n",
       "      <td>0.004891</td>\n",
       "      <td>0.919861</td>\n",
       "      <td>0.007315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count N-grams (1,16) logistic</th>\n",
       "      <td>0.830456</td>\n",
       "      <td>0.004370</td>\n",
       "      <td>0.919778</td>\n",
       "      <td>0.007307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count N-grams (1,17) logistic</th>\n",
       "      <td>0.832026</td>\n",
       "      <td>0.003570</td>\n",
       "      <td>0.919669</td>\n",
       "      <td>0.007312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count N-grams (1,18) logistic</th>\n",
       "      <td>0.832026</td>\n",
       "      <td>0.003570</td>\n",
       "      <td>0.919578</td>\n",
       "      <td>0.007304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count N-grams (1,19) logistic</th>\n",
       "      <td>0.831633</td>\n",
       "      <td>0.003424</td>\n",
       "      <td>0.919490</td>\n",
       "      <td>0.007298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count N-grams (1,20) logistic</th>\n",
       "      <td>0.831633</td>\n",
       "      <td>0.003424</td>\n",
       "      <td>0.919403</td>\n",
       "      <td>0.007311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count N-grams (1,21) logistic</th>\n",
       "      <td>0.829673</td>\n",
       "      <td>0.004347</td>\n",
       "      <td>0.919318</td>\n",
       "      <td>0.007299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count N-grams (1,22) logistic</th>\n",
       "      <td>0.829673</td>\n",
       "      <td>0.004347</td>\n",
       "      <td>0.919253</td>\n",
       "      <td>0.007300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count N-grams (1,23) logistic</th>\n",
       "      <td>0.829673</td>\n",
       "      <td>0.004347</td>\n",
       "      <td>0.919220</td>\n",
       "      <td>0.007319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count N-grams (1,24) logistic</th>\n",
       "      <td>0.830065</td>\n",
       "      <td>0.004665</td>\n",
       "      <td>0.919209</td>\n",
       "      <td>0.007319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count N-grams (1,25) logistic</th>\n",
       "      <td>0.829673</td>\n",
       "      <td>0.005215</td>\n",
       "      <td>0.919183</td>\n",
       "      <td>0.007334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count N-grams (1,26) logistic</th>\n",
       "      <td>0.829673</td>\n",
       "      <td>0.005215</td>\n",
       "      <td>0.919162</td>\n",
       "      <td>0.007337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count N-grams (1,27) logistic</th>\n",
       "      <td>0.830065</td>\n",
       "      <td>0.005567</td>\n",
       "      <td>0.919151</td>\n",
       "      <td>0.007350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count N-grams (1,28) logistic</th>\n",
       "      <td>0.830065</td>\n",
       "      <td>0.005567</td>\n",
       "      <td>0.919114</td>\n",
       "      <td>0.007368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count N-grams (1,29) logistic</th>\n",
       "      <td>0.830065</td>\n",
       "      <td>0.005567</td>\n",
       "      <td>0.919111</td>\n",
       "      <td>0.007379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Accuracy  Accuracy_std   ROC_AUC  \\\n",
       "Count Logistic                            0.774007      0.022582  0.831514   \n",
       "Count Logistic                            0.817895      0.010648  0.897232   \n",
       "Count NLTK English stopwords logistic     0.812407      0.008775  0.891127   \n",
       "Count Sklearn English stopwords logistic  0.804168      0.009856  0.887977   \n",
       "Count N-grams (1,2) logistic              0.830850      0.014552  0.917302   \n",
       "Count N-grams (1,3) logistic              0.834383      0.013282  0.921745   \n",
       "Count N-grams (1,4) logistic              0.835168      0.008305  0.922530   \n",
       "Count N-grams (1,5) logistic              0.836348      0.009070  0.922453   \n",
       "Count N-grams (1,6) logistic              0.835562      0.006268  0.922177   \n",
       "Count N-grams (1,7) logistic              0.834383      0.006013  0.921943   \n",
       "Count N-grams (1,8) logistic              0.832813      0.006659  0.921537   \n",
       "Count N-grams (1,9) logistic              0.831635      0.004902  0.921291   \n",
       "Count N-grams (1,10) logistic             0.831243      0.005457  0.921062   \n",
       "Count N-grams (1,11) logistic             0.831636      0.006566  0.920707   \n",
       "Count N-grams (1,12) logistic             0.833207      0.006851  0.920408   \n",
       "Count N-grams (1,13) logistic             0.832814      0.006567  0.920240   \n",
       "Count N-grams (1,14) logistic             0.832813      0.005768  0.920085   \n",
       "Count N-grams (1,15) logistic             0.831241      0.004891  0.919861   \n",
       "Count N-grams (1,16) logistic             0.830456      0.004370  0.919778   \n",
       "Count N-grams (1,17) logistic             0.832026      0.003570  0.919669   \n",
       "Count N-grams (1,18) logistic             0.832026      0.003570  0.919578   \n",
       "Count N-grams (1,19) logistic             0.831633      0.003424  0.919490   \n",
       "Count N-grams (1,20) logistic             0.831633      0.003424  0.919403   \n",
       "Count N-grams (1,21) logistic             0.829673      0.004347  0.919318   \n",
       "Count N-grams (1,22) logistic             0.829673      0.004347  0.919253   \n",
       "Count N-grams (1,23) logistic             0.829673      0.004347  0.919220   \n",
       "Count N-grams (1,24) logistic             0.830065      0.004665  0.919209   \n",
       "Count N-grams (1,25) logistic             0.829673      0.005215  0.919183   \n",
       "Count N-grams (1,26) logistic             0.829673      0.005215  0.919162   \n",
       "Count N-grams (1,27) logistic             0.830065      0.005567  0.919151   \n",
       "Count N-grams (1,28) logistic             0.830065      0.005567  0.919114   \n",
       "Count N-grams (1,29) logistic             0.830065      0.005567  0.919111   \n",
       "\n",
       "                                          ROC_AUC_std  \n",
       "Count Logistic                               0.020428  \n",
       "Count Logistic                               0.009240  \n",
       "Count NLTK English stopwords logistic        0.005639  \n",
       "Count Sklearn English stopwords logistic     0.005197  \n",
       "Count N-grams (1,2) logistic                 0.006241  \n",
       "Count N-grams (1,3) logistic                 0.005949  \n",
       "Count N-grams (1,4) logistic                 0.006164  \n",
       "Count N-grams (1,5) logistic                 0.006407  \n",
       "Count N-grams (1,6) logistic                 0.006631  \n",
       "Count N-grams (1,7) logistic                 0.006697  \n",
       "Count N-grams (1,8) logistic                 0.006950  \n",
       "Count N-grams (1,9) logistic                 0.007067  \n",
       "Count N-grams (1,10) logistic                0.007077  \n",
       "Count N-grams (1,11) logistic                0.007235  \n",
       "Count N-grams (1,12) logistic                0.007238  \n",
       "Count N-grams (1,13) logistic                0.007248  \n",
       "Count N-grams (1,14) logistic                0.007259  \n",
       "Count N-grams (1,15) logistic                0.007315  \n",
       "Count N-grams (1,16) logistic                0.007307  \n",
       "Count N-grams (1,17) logistic                0.007312  \n",
       "Count N-grams (1,18) logistic                0.007304  \n",
       "Count N-grams (1,19) logistic                0.007298  \n",
       "Count N-grams (1,20) logistic                0.007311  \n",
       "Count N-grams (1,21) logistic                0.007299  \n",
       "Count N-grams (1,22) logistic                0.007300  \n",
       "Count N-grams (1,23) logistic                0.007319  \n",
       "Count N-grams (1,24) logistic                0.007319  \n",
       "Count N-grams (1,25) logistic                0.007334  \n",
       "Count N-grams (1,26) logistic                0.007337  \n",
       "Count N-grams (1,27) logistic                0.007350  \n",
       "Count N-grams (1,28) logistic                0.007368  \n",
       "Count N-grams (1,29) logistic                0.007379  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_ngram = results\n",
    "for max_ngram in range(2, 30):\n",
    "    sklearn_count_ngram = Pipeline([\n",
    "        (\"vectorize\", CountVectorizer(analyzer=\"word\", ngram_range=(1, max_ngram))),\n",
    "        (\"model\", LogisticRegression(random_state=seed))\n",
    "    ])\n",
    "    results_ngram = score_model_oversampling(\n",
    "        \"Count N-grams (1,{0}) logistic\".format(max_ngram),\n",
    "        sklearn_count_ngram,\n",
    "        results_ngram,\n",
    "        result_columns,\n",
    "        False\n",
    "    )\n",
    "results_ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "\tAverage: 0.836\n",
      "\tStandard Deviation: 0.009\n",
      "ROC AUC:\n",
      "\tAverage: 0.922\n",
      "\tStandard Deviation: 0.006\n"
     ]
    }
   ],
   "source": [
    "sklearn_count_ngram_1_5 = Pipeline([\n",
    "    (\"vectorize\", CountVectorizer(analyzer=\"word\", ngram_range=(1, 5))),\n",
    "    (\"model\", LogisticRegression(random_state=seed))\n",
    "])\n",
    "results = score_model_oversampling(\n",
    "    \"Count N-grams (1,5) logistic\",\n",
    "    sklearn_count_ngram_1_5,\n",
    "    results,\n",
    "    result_columns\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "\tAverage: 0.805\n",
      "\tStandard Deviation: 0.009\n",
      "ROC AUC:\n",
      "\tAverage: 0.894\n",
      "\tStandard Deviation: 0.005\n"
     ]
    }
   ],
   "source": [
    "tfidf_logistic_pipe = Pipeline([\n",
    "    (\"vectorize\", TfidfVectorizer()),\n",
    "    (\"model\", LogisticRegression(random_state=seed))])\n",
    "results = score_model_oversampling(\n",
    "    \"TF-IDF Logistic baseline\",\n",
    "    tfidf_logistic_pipe,\n",
    "    results,\n",
    "    result_columns\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### English stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "\tAverage: 0.801\n",
      "\tStandard Deviation: 0.009\n",
      "ROC AUC:\n",
      "\tAverage: 0.885\n",
      "\tStandard Deviation: 0.006\n"
     ]
    }
   ],
   "source": [
    "english_stopwords = stopwords.words(\"english\")\n",
    "nltk_stopwords_tfidf_logistic = Pipeline([\n",
    "    (\"vectorize\", TfidfVectorizer(stop_words=english_stopwords)),\n",
    "    (\"model\", LogisticRegression(random_state=seed))\n",
    "])\n",
    "results = score_model_oversampling(\n",
    "    \"Tfidf NLTK English stopwords logistic\",\n",
    "    nltk_stopwords_tfidf_logistic,\n",
    "    results,\n",
    "    result_columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "\tAverage: 0.792\n",
      "\tStandard Deviation: 0.003\n",
      "ROC AUC:\n",
      "\tAverage: 0.879\n",
      "\tStandard Deviation: 0.004\n"
     ]
    }
   ],
   "source": [
    "sklearn_stopwords_tfidf_logistic = Pipeline([\n",
    "    (\"vectorize\", TfidfVectorizer(stop_words=\"english\")),\n",
    "    (\"model\", LogisticRegression(random_state=seed))\n",
    "])\n",
    "results = score_model_oversampling(\n",
    "    \"Tfidf Sklearn English stopwords logistic\",\n",
    "    sklearn_stopwords_tfidf_logistic,\n",
    "    results,\n",
    "    result_columns\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Accuracy_std</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>ROC_AUC_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Count Logistic</th>\n",
       "      <td>0.774007</td>\n",
       "      <td>0.022582</td>\n",
       "      <td>0.831514</td>\n",
       "      <td>0.020428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count Logistic</th>\n",
       "      <td>0.817895</td>\n",
       "      <td>0.010648</td>\n",
       "      <td>0.897232</td>\n",
       "      <td>0.009240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count NLTK English stopwords logistic</th>\n",
       "      <td>0.812407</td>\n",
       "      <td>0.008775</td>\n",
       "      <td>0.891127</td>\n",
       "      <td>0.005639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count Sklearn English stopwords logistic</th>\n",
       "      <td>0.804168</td>\n",
       "      <td>0.009856</td>\n",
       "      <td>0.887977</td>\n",
       "      <td>0.005197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count N-grams (1,5) logistic</th>\n",
       "      <td>0.836348</td>\n",
       "      <td>0.009070</td>\n",
       "      <td>0.922453</td>\n",
       "      <td>0.006407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TF-IDF Logistic baseline</th>\n",
       "      <td>0.805341</td>\n",
       "      <td>0.008842</td>\n",
       "      <td>0.894245</td>\n",
       "      <td>0.005339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf NLTK English stopwords logistic</th>\n",
       "      <td>0.801015</td>\n",
       "      <td>0.008513</td>\n",
       "      <td>0.884795</td>\n",
       "      <td>0.005838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf Sklearn English stopwords logistic</th>\n",
       "      <td>0.791995</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>0.878878</td>\n",
       "      <td>0.004080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf N-grams (1,2) logistic</th>\n",
       "      <td>0.824172</td>\n",
       "      <td>0.009687</td>\n",
       "      <td>0.912338</td>\n",
       "      <td>0.006352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf N-grams (1,3) logistic</th>\n",
       "      <td>0.829276</td>\n",
       "      <td>0.005149</td>\n",
       "      <td>0.918082</td>\n",
       "      <td>0.007182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf N-grams (1,4) logistic</th>\n",
       "      <td>0.832026</td>\n",
       "      <td>0.001956</td>\n",
       "      <td>0.920773</td>\n",
       "      <td>0.007653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf N-grams (1,5) logistic</th>\n",
       "      <td>0.835951</td>\n",
       "      <td>0.002134</td>\n",
       "      <td>0.922692</td>\n",
       "      <td>0.007972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf N-grams (1,6) logistic</th>\n",
       "      <td>0.837519</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.923966</td>\n",
       "      <td>0.008160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf N-grams (1,7) logistic</th>\n",
       "      <td>0.839481</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>0.924965</td>\n",
       "      <td>0.008373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf N-grams (1,8) logistic</th>\n",
       "      <td>0.841835</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>0.925871</td>\n",
       "      <td>0.008521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf N-grams (1,9) logistic</th>\n",
       "      <td>0.843405</td>\n",
       "      <td>0.001758</td>\n",
       "      <td>0.926411</td>\n",
       "      <td>0.008566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf N-grams (1,10) logistic</th>\n",
       "      <td>0.844191</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>0.926921</td>\n",
       "      <td>0.008676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf N-grams (1,11) logistic</th>\n",
       "      <td>0.844584</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.927296</td>\n",
       "      <td>0.008669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf N-grams (1,12) logistic</th>\n",
       "      <td>0.843799</td>\n",
       "      <td>0.001959</td>\n",
       "      <td>0.927553</td>\n",
       "      <td>0.008681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf N-grams (1,13) logistic</th>\n",
       "      <td>0.844585</td>\n",
       "      <td>0.002491</td>\n",
       "      <td>0.927858</td>\n",
       "      <td>0.008757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf N-grams (1,14) logistic</th>\n",
       "      <td>0.844587</td>\n",
       "      <td>0.004909</td>\n",
       "      <td>0.928032</td>\n",
       "      <td>0.008772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf N-grams (1,15) logistic</th>\n",
       "      <td>0.844587</td>\n",
       "      <td>0.004975</td>\n",
       "      <td>0.928175</td>\n",
       "      <td>0.008797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf N-grams (1,16) logistic</th>\n",
       "      <td>0.844196</td>\n",
       "      <td>0.005745</td>\n",
       "      <td>0.928258</td>\n",
       "      <td>0.008790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf N-grams (1,17) logistic</th>\n",
       "      <td>0.843804</td>\n",
       "      <td>0.005656</td>\n",
       "      <td>0.928354</td>\n",
       "      <td>0.008816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf N-grams (1,18) logistic</th>\n",
       "      <td>0.843804</td>\n",
       "      <td>0.005656</td>\n",
       "      <td>0.928415</td>\n",
       "      <td>0.008863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf N-grams (1,19) logistic</th>\n",
       "      <td>0.843804</td>\n",
       "      <td>0.006274</td>\n",
       "      <td>0.928476</td>\n",
       "      <td>0.008868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf N-grams (1,20) logistic</th>\n",
       "      <td>0.843804</td>\n",
       "      <td>0.006274</td>\n",
       "      <td>0.928498</td>\n",
       "      <td>0.008869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf N-grams (1,21) logistic</th>\n",
       "      <td>0.843804</td>\n",
       "      <td>0.006274</td>\n",
       "      <td>0.928498</td>\n",
       "      <td>0.008888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf N-grams (1,22) logistic</th>\n",
       "      <td>0.842628</td>\n",
       "      <td>0.006103</td>\n",
       "      <td>0.928530</td>\n",
       "      <td>0.008859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf N-grams (1,23) logistic</th>\n",
       "      <td>0.843412</td>\n",
       "      <td>0.005620</td>\n",
       "      <td>0.928544</td>\n",
       "      <td>0.008858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf N-grams (1,24) logistic</th>\n",
       "      <td>0.843804</td>\n",
       "      <td>0.005143</td>\n",
       "      <td>0.928594</td>\n",
       "      <td>0.008883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf N-grams (1,25) logistic</th>\n",
       "      <td>0.842628</td>\n",
       "      <td>0.005465</td>\n",
       "      <td>0.928605</td>\n",
       "      <td>0.008864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf N-grams (1,26) logistic</th>\n",
       "      <td>0.842628</td>\n",
       "      <td>0.005465</td>\n",
       "      <td>0.928635</td>\n",
       "      <td>0.008871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf N-grams (1,27) logistic</th>\n",
       "      <td>0.843020</td>\n",
       "      <td>0.005302</td>\n",
       "      <td>0.928657</td>\n",
       "      <td>0.008857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf N-grams (1,28) logistic</th>\n",
       "      <td>0.843020</td>\n",
       "      <td>0.005302</td>\n",
       "      <td>0.928644</td>\n",
       "      <td>0.008860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf N-grams (1,29) logistic</th>\n",
       "      <td>0.843412</td>\n",
       "      <td>0.005194</td>\n",
       "      <td>0.928644</td>\n",
       "      <td>0.008870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Accuracy  Accuracy_std   ROC_AUC  \\\n",
       "Count Logistic                            0.774007      0.022582  0.831514   \n",
       "Count Logistic                            0.817895      0.010648  0.897232   \n",
       "Count NLTK English stopwords logistic     0.812407      0.008775  0.891127   \n",
       "Count Sklearn English stopwords logistic  0.804168      0.009856  0.887977   \n",
       "Count N-grams (1,5) logistic              0.836348      0.009070  0.922453   \n",
       "TF-IDF Logistic baseline                  0.805341      0.008842  0.894245   \n",
       "Tfidf NLTK English stopwords logistic     0.801015      0.008513  0.884795   \n",
       "Tfidf Sklearn English stopwords logistic  0.791995      0.002666  0.878878   \n",
       "Tfidf N-grams (1,2) logistic              0.824172      0.009687  0.912338   \n",
       "Tfidf N-grams (1,3) logistic              0.829276      0.005149  0.918082   \n",
       "Tfidf N-grams (1,4) logistic              0.832026      0.001956  0.920773   \n",
       "Tfidf N-grams (1,5) logistic              0.835951      0.002134  0.922692   \n",
       "Tfidf N-grams (1,6) logistic              0.837519      0.000181  0.923966   \n",
       "Tfidf N-grams (1,7) logistic              0.839481      0.001209  0.924965   \n",
       "Tfidf N-grams (1,8) logistic              0.841835      0.001636  0.925871   \n",
       "Tfidf N-grams (1,9) logistic              0.843405      0.001758  0.926411   \n",
       "Tfidf N-grams (1,10) logistic             0.844191      0.000729  0.926921   \n",
       "Tfidf N-grams (1,11) logistic             0.844584      0.000173  0.927296   \n",
       "Tfidf N-grams (1,12) logistic             0.843799      0.001959  0.927553   \n",
       "Tfidf N-grams (1,13) logistic             0.844585      0.002491  0.927858   \n",
       "Tfidf N-grams (1,14) logistic             0.844587      0.004909  0.928032   \n",
       "Tfidf N-grams (1,15) logistic             0.844587      0.004975  0.928175   \n",
       "Tfidf N-grams (1,16) logistic             0.844196      0.005745  0.928258   \n",
       "Tfidf N-grams (1,17) logistic             0.843804      0.005656  0.928354   \n",
       "Tfidf N-grams (1,18) logistic             0.843804      0.005656  0.928415   \n",
       "Tfidf N-grams (1,19) logistic             0.843804      0.006274  0.928476   \n",
       "Tfidf N-grams (1,20) logistic             0.843804      0.006274  0.928498   \n",
       "Tfidf N-grams (1,21) logistic             0.843804      0.006274  0.928498   \n",
       "Tfidf N-grams (1,22) logistic             0.842628      0.006103  0.928530   \n",
       "Tfidf N-grams (1,23) logistic             0.843412      0.005620  0.928544   \n",
       "Tfidf N-grams (1,24) logistic             0.843804      0.005143  0.928594   \n",
       "Tfidf N-grams (1,25) logistic             0.842628      0.005465  0.928605   \n",
       "Tfidf N-grams (1,26) logistic             0.842628      0.005465  0.928635   \n",
       "Tfidf N-grams (1,27) logistic             0.843020      0.005302  0.928657   \n",
       "Tfidf N-grams (1,28) logistic             0.843020      0.005302  0.928644   \n",
       "Tfidf N-grams (1,29) logistic             0.843412      0.005194  0.928644   \n",
       "\n",
       "                                          ROC_AUC_std  \n",
       "Count Logistic                               0.020428  \n",
       "Count Logistic                               0.009240  \n",
       "Count NLTK English stopwords logistic        0.005639  \n",
       "Count Sklearn English stopwords logistic     0.005197  \n",
       "Count N-grams (1,5) logistic                 0.006407  \n",
       "TF-IDF Logistic baseline                     0.005339  \n",
       "Tfidf NLTK English stopwords logistic        0.005838  \n",
       "Tfidf Sklearn English stopwords logistic     0.004080  \n",
       "Tfidf N-grams (1,2) logistic                 0.006352  \n",
       "Tfidf N-grams (1,3) logistic                 0.007182  \n",
       "Tfidf N-grams (1,4) logistic                 0.007653  \n",
       "Tfidf N-grams (1,5) logistic                 0.007972  \n",
       "Tfidf N-grams (1,6) logistic                 0.008160  \n",
       "Tfidf N-grams (1,7) logistic                 0.008373  \n",
       "Tfidf N-grams (1,8) logistic                 0.008521  \n",
       "Tfidf N-grams (1,9) logistic                 0.008566  \n",
       "Tfidf N-grams (1,10) logistic                0.008676  \n",
       "Tfidf N-grams (1,11) logistic                0.008669  \n",
       "Tfidf N-grams (1,12) logistic                0.008681  \n",
       "Tfidf N-grams (1,13) logistic                0.008757  \n",
       "Tfidf N-grams (1,14) logistic                0.008772  \n",
       "Tfidf N-grams (1,15) logistic                0.008797  \n",
       "Tfidf N-grams (1,16) logistic                0.008790  \n",
       "Tfidf N-grams (1,17) logistic                0.008816  \n",
       "Tfidf N-grams (1,18) logistic                0.008863  \n",
       "Tfidf N-grams (1,19) logistic                0.008868  \n",
       "Tfidf N-grams (1,20) logistic                0.008869  \n",
       "Tfidf N-grams (1,21) logistic                0.008888  \n",
       "Tfidf N-grams (1,22) logistic                0.008859  \n",
       "Tfidf N-grams (1,23) logistic                0.008858  \n",
       "Tfidf N-grams (1,24) logistic                0.008883  \n",
       "Tfidf N-grams (1,25) logistic                0.008864  \n",
       "Tfidf N-grams (1,26) logistic                0.008871  \n",
       "Tfidf N-grams (1,27) logistic                0.008857  \n",
       "Tfidf N-grams (1,28) logistic                0.008860  \n",
       "Tfidf N-grams (1,29) logistic                0.008870  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_ngram = results\n",
    "for max_ngram in range(2, 30):\n",
    "    sklearn_tfidf_ngram = Pipeline([\n",
    "        (\"vectorize\", TfidfVectorizer(analyzer=\"word\", ngram_range=(1, max_ngram))),\n",
    "        (\"model\", LogisticRegression(random_state=seed))\n",
    "    ])\n",
    "    results_ngram = score_model_oversampling(\n",
    "        \"Tfidf N-grams (1,{0}) logistic\".format(max_ngram),\n",
    "        sklearn_tfidf_ngram,\n",
    "        results_ngram,\n",
    "        result_columns,\n",
    "        False\n",
    "    )\n",
    "results_ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Accuracy_std</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>ROC_AUC_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Count Logistic</th>\n",
       "      <td>0.774007</td>\n",
       "      <td>0.022582</td>\n",
       "      <td>0.831514</td>\n",
       "      <td>0.020428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count Logistic</th>\n",
       "      <td>0.817895</td>\n",
       "      <td>0.010648</td>\n",
       "      <td>0.897232</td>\n",
       "      <td>0.009240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count NLTK English stopwords logistic</th>\n",
       "      <td>0.812407</td>\n",
       "      <td>0.008775</td>\n",
       "      <td>0.891127</td>\n",
       "      <td>0.005639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count Sklearn English stopwords logistic</th>\n",
       "      <td>0.804168</td>\n",
       "      <td>0.009856</td>\n",
       "      <td>0.887977</td>\n",
       "      <td>0.005197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count N-grams (1,5) logistic</th>\n",
       "      <td>0.836348</td>\n",
       "      <td>0.009070</td>\n",
       "      <td>0.922453</td>\n",
       "      <td>0.006407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TF-IDF Logistic baseline</th>\n",
       "      <td>0.805341</td>\n",
       "      <td>0.008842</td>\n",
       "      <td>0.894245</td>\n",
       "      <td>0.005339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf NLTK English stopwords logistic</th>\n",
       "      <td>0.801015</td>\n",
       "      <td>0.008513</td>\n",
       "      <td>0.884795</td>\n",
       "      <td>0.005838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf Sklearn English stopwords logistic</th>\n",
       "      <td>0.791995</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>0.878878</td>\n",
       "      <td>0.004080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf N-grams (2, 6) logistic</th>\n",
       "      <td>0.823398</td>\n",
       "      <td>0.006749</td>\n",
       "      <td>0.911101</td>\n",
       "      <td>0.007006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf N-grams (3, 6) logistic</th>\n",
       "      <td>0.799462</td>\n",
       "      <td>0.010065</td>\n",
       "      <td>0.869869</td>\n",
       "      <td>0.012304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf N-grams (4, 6) logistic</th>\n",
       "      <td>0.784942</td>\n",
       "      <td>0.011957</td>\n",
       "      <td>0.825995</td>\n",
       "      <td>0.011328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf N-grams (5, 6) logistic</th>\n",
       "      <td>0.773170</td>\n",
       "      <td>0.013025</td>\n",
       "      <td>0.789476</td>\n",
       "      <td>0.009737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Accuracy  Accuracy_std   ROC_AUC  \\\n",
       "Count Logistic                            0.774007      0.022582  0.831514   \n",
       "Count Logistic                            0.817895      0.010648  0.897232   \n",
       "Count NLTK English stopwords logistic     0.812407      0.008775  0.891127   \n",
       "Count Sklearn English stopwords logistic  0.804168      0.009856  0.887977   \n",
       "Count N-grams (1,5) logistic              0.836348      0.009070  0.922453   \n",
       "TF-IDF Logistic baseline                  0.805341      0.008842  0.894245   \n",
       "Tfidf NLTK English stopwords logistic     0.801015      0.008513  0.884795   \n",
       "Tfidf Sklearn English stopwords logistic  0.791995      0.002666  0.878878   \n",
       "Tfidf N-grams (2, 6) logistic             0.823398      0.006749  0.911101   \n",
       "Tfidf N-grams (3, 6) logistic             0.799462      0.010065  0.869869   \n",
       "Tfidf N-grams (4, 6) logistic             0.784942      0.011957  0.825995   \n",
       "Tfidf N-grams (5, 6) logistic             0.773170      0.013025  0.789476   \n",
       "\n",
       "                                          ROC_AUC_std  \n",
       "Count Logistic                               0.020428  \n",
       "Count Logistic                               0.009240  \n",
       "Count NLTK English stopwords logistic        0.005639  \n",
       "Count Sklearn English stopwords logistic     0.005197  \n",
       "Count N-grams (1,5) logistic                 0.006407  \n",
       "TF-IDF Logistic baseline                     0.005339  \n",
       "Tfidf NLTK English stopwords logistic        0.005838  \n",
       "Tfidf Sklearn English stopwords logistic     0.004080  \n",
       "Tfidf N-grams (2, 6) logistic                0.007006  \n",
       "Tfidf N-grams (3, 6) logistic                0.012304  \n",
       "Tfidf N-grams (4, 6) logistic                0.011328  \n",
       "Tfidf N-grams (5, 6) logistic                0.009737  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_ngram = results\n",
    "for min_ngram in range(2, 6):\n",
    "    sklearn_tfidf_ngram = Pipeline([\n",
    "        (\"vectorize\", TfidfVectorizer(analyzer=\"word\", ngram_range=(min_ngram, 6))),\n",
    "        (\"model\", LogisticRegression(random_state=seed))\n",
    "    ])\n",
    "    results_ngram = score_model_oversampling(\n",
    "        \"Tfidf N-grams ({0}, 6) logistic\".format(min_ngram),\n",
    "        sklearn_tfidf_ngram,\n",
    "        results_ngram,\n",
    "        result_columns,\n",
    "        False\n",
    "    )\n",
    "results_ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "\tAverage: 0.838\n",
      "\tStandard Deviation: 0.000\n",
      "ROC AUC:\n",
      "\tAverage: 0.924\n",
      "\tStandard Deviation: 0.008\n"
     ]
    }
   ],
   "source": [
    "sklearn_tfidf_ngram_1_6 = Pipeline([\n",
    "    (\"vectorize\", TfidfVectorizer(analyzer=\"word\", ngram_range=(1, 6))),\n",
    "    (\"model\", LogisticRegression(random_state=seed))\n",
    "])\n",
    "results = score_model_oversampling(\n",
    "    \"Tfidf N-grams (1,6) logistic\",\n",
    "    sklearn_tfidf_ngram_1_6,\n",
    "    results,\n",
    "    result_columns\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Accuracy_std</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>ROC_AUC_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Count Logistic</th>\n",
       "      <td>0.774007</td>\n",
       "      <td>0.022582</td>\n",
       "      <td>0.831514</td>\n",
       "      <td>0.020428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count Logistic</th>\n",
       "      <td>0.817895</td>\n",
       "      <td>0.010648</td>\n",
       "      <td>0.897232</td>\n",
       "      <td>0.009240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count NLTK English stopwords logistic</th>\n",
       "      <td>0.812407</td>\n",
       "      <td>0.008775</td>\n",
       "      <td>0.891127</td>\n",
       "      <td>0.005639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count Sklearn English stopwords logistic</th>\n",
       "      <td>0.804168</td>\n",
       "      <td>0.009856</td>\n",
       "      <td>0.887977</td>\n",
       "      <td>0.005197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count N-grams (1,5) logistic</th>\n",
       "      <td>0.836348</td>\n",
       "      <td>0.009070</td>\n",
       "      <td>0.922453</td>\n",
       "      <td>0.006407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TF-IDF Logistic baseline</th>\n",
       "      <td>0.805341</td>\n",
       "      <td>0.008842</td>\n",
       "      <td>0.894245</td>\n",
       "      <td>0.005339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf NLTK English stopwords logistic</th>\n",
       "      <td>0.801015</td>\n",
       "      <td>0.008513</td>\n",
       "      <td>0.884795</td>\n",
       "      <td>0.005838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf Sklearn English stopwords logistic</th>\n",
       "      <td>0.791995</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>0.878878</td>\n",
       "      <td>0.004080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf N-grams (1,6) logistic</th>\n",
       "      <td>0.837519</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.923966</td>\n",
       "      <td>0.008160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regularized TF-IDF logistic. C=0.1</th>\n",
       "      <td>0.830064</td>\n",
       "      <td>0.003026</td>\n",
       "      <td>0.913138</td>\n",
       "      <td>0.008781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regularized TF-IDF logistic. C=0.2</th>\n",
       "      <td>0.830455</td>\n",
       "      <td>0.001930</td>\n",
       "      <td>0.915289</td>\n",
       "      <td>0.008683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regularized TF-IDF logistic. C=0.3</th>\n",
       "      <td>0.829671</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.917112</td>\n",
       "      <td>0.008597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regularized TF-IDF logistic. C=0.4</th>\n",
       "      <td>0.832420</td>\n",
       "      <td>0.001822</td>\n",
       "      <td>0.918441</td>\n",
       "      <td>0.008582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regularized TF-IDF logistic. C=0.5</th>\n",
       "      <td>0.834382</td>\n",
       "      <td>0.002253</td>\n",
       "      <td>0.919762</td>\n",
       "      <td>0.008525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regularized TF-IDF logistic. C=0.6</th>\n",
       "      <td>0.834380</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.920743</td>\n",
       "      <td>0.008453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regularized TF-IDF logistic. C=0.7</th>\n",
       "      <td>0.835165</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.921725</td>\n",
       "      <td>0.008469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regularized TF-IDF logistic. C=0.8</th>\n",
       "      <td>0.836734</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>0.922593</td>\n",
       "      <td>0.008359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regularized TF-IDF logistic. C=0.9</th>\n",
       "      <td>0.836733</td>\n",
       "      <td>0.001292</td>\n",
       "      <td>0.923234</td>\n",
       "      <td>0.008295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regularized TF-IDF logistic. C=1.0</th>\n",
       "      <td>0.837519</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.923966</td>\n",
       "      <td>0.008160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regularized TF-IDF logistic. C=1.1</th>\n",
       "      <td>0.837913</td>\n",
       "      <td>0.001031</td>\n",
       "      <td>0.924469</td>\n",
       "      <td>0.008123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regularized TF-IDF logistic. C=1.2</th>\n",
       "      <td>0.838698</td>\n",
       "      <td>0.001582</td>\n",
       "      <td>0.924973</td>\n",
       "      <td>0.008079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regularized TF-IDF logistic. C=1.3</th>\n",
       "      <td>0.839090</td>\n",
       "      <td>0.001958</td>\n",
       "      <td>0.925467</td>\n",
       "      <td>0.008045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regularized TF-IDF logistic. C=1.4</th>\n",
       "      <td>0.840267</td>\n",
       "      <td>0.001958</td>\n",
       "      <td>0.925929</td>\n",
       "      <td>0.007998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regularized TF-IDF logistic. C=1.5</th>\n",
       "      <td>0.840659</td>\n",
       "      <td>0.001444</td>\n",
       "      <td>0.926294</td>\n",
       "      <td>0.007919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regularized TF-IDF logistic. C=1.6</th>\n",
       "      <td>0.841053</td>\n",
       "      <td>0.001583</td>\n",
       "      <td>0.926647</td>\n",
       "      <td>0.007854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regularized TF-IDF logistic. C=1.7</th>\n",
       "      <td>0.840659</td>\n",
       "      <td>0.001444</td>\n",
       "      <td>0.926961</td>\n",
       "      <td>0.007853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regularized TF-IDF logistic. C=1.8</th>\n",
       "      <td>0.840266</td>\n",
       "      <td>0.001511</td>\n",
       "      <td>0.927255</td>\n",
       "      <td>0.007870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regularized TF-IDF logistic. C=1.9</th>\n",
       "      <td>0.839874</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.927568</td>\n",
       "      <td>0.007865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Accuracy  Accuracy_std   ROC_AUC  \\\n",
       "Count Logistic                            0.774007      0.022582  0.831514   \n",
       "Count Logistic                            0.817895      0.010648  0.897232   \n",
       "Count NLTK English stopwords logistic     0.812407      0.008775  0.891127   \n",
       "Count Sklearn English stopwords logistic  0.804168      0.009856  0.887977   \n",
       "Count N-grams (1,5) logistic              0.836348      0.009070  0.922453   \n",
       "TF-IDF Logistic baseline                  0.805341      0.008842  0.894245   \n",
       "Tfidf NLTK English stopwords logistic     0.801015      0.008513  0.884795   \n",
       "Tfidf Sklearn English stopwords logistic  0.791995      0.002666  0.878878   \n",
       "Tfidf N-grams (1,6) logistic              0.837519      0.000181  0.923966   \n",
       "Regularized TF-IDF logistic. C=0.1        0.830064      0.003026  0.913138   \n",
       "Regularized TF-IDF logistic. C=0.2        0.830455      0.001930  0.915289   \n",
       "Regularized TF-IDF logistic. C=0.3        0.829671      0.000366  0.917112   \n",
       "Regularized TF-IDF logistic. C=0.4        0.832420      0.001822  0.918441   \n",
       "Regularized TF-IDF logistic. C=0.5        0.834382      0.002253  0.919762   \n",
       "Regularized TF-IDF logistic. C=0.6        0.834380      0.000371  0.920743   \n",
       "Regularized TF-IDF logistic. C=0.7        0.835165      0.000183  0.921725   \n",
       "Regularized TF-IDF logistic. C=0.8        0.836734      0.000664  0.922593   \n",
       "Regularized TF-IDF logistic. C=0.9        0.836733      0.001292  0.923234   \n",
       "Regularized TF-IDF logistic. C=1.0        0.837519      0.000181  0.923966   \n",
       "Regularized TF-IDF logistic. C=1.1        0.837913      0.001031  0.924469   \n",
       "Regularized TF-IDF logistic. C=1.2        0.838698      0.001582  0.924973   \n",
       "Regularized TF-IDF logistic. C=1.3        0.839090      0.001958  0.925467   \n",
       "Regularized TF-IDF logistic. C=1.4        0.840267      0.001958  0.925929   \n",
       "Regularized TF-IDF logistic. C=1.5        0.840659      0.001444  0.926294   \n",
       "Regularized TF-IDF logistic. C=1.6        0.841053      0.001583  0.926647   \n",
       "Regularized TF-IDF logistic. C=1.7        0.840659      0.001444  0.926961   \n",
       "Regularized TF-IDF logistic. C=1.8        0.840266      0.001511  0.927255   \n",
       "Regularized TF-IDF logistic. C=1.9        0.839874      0.000977  0.927568   \n",
       "\n",
       "                                          ROC_AUC_std  \n",
       "Count Logistic                               0.020428  \n",
       "Count Logistic                               0.009240  \n",
       "Count NLTK English stopwords logistic        0.005639  \n",
       "Count Sklearn English stopwords logistic     0.005197  \n",
       "Count N-grams (1,5) logistic                 0.006407  \n",
       "TF-IDF Logistic baseline                     0.005339  \n",
       "Tfidf NLTK English stopwords logistic        0.005838  \n",
       "Tfidf Sklearn English stopwords logistic     0.004080  \n",
       "Tfidf N-grams (1,6) logistic                 0.008160  \n",
       "Regularized TF-IDF logistic. C=0.1           0.008781  \n",
       "Regularized TF-IDF logistic. C=0.2           0.008683  \n",
       "Regularized TF-IDF logistic. C=0.3           0.008597  \n",
       "Regularized TF-IDF logistic. C=0.4           0.008582  \n",
       "Regularized TF-IDF logistic. C=0.5           0.008525  \n",
       "Regularized TF-IDF logistic. C=0.6           0.008453  \n",
       "Regularized TF-IDF logistic. C=0.7           0.008469  \n",
       "Regularized TF-IDF logistic. C=0.8           0.008359  \n",
       "Regularized TF-IDF logistic. C=0.9           0.008295  \n",
       "Regularized TF-IDF logistic. C=1.0           0.008160  \n",
       "Regularized TF-IDF logistic. C=1.1           0.008123  \n",
       "Regularized TF-IDF logistic. C=1.2           0.008079  \n",
       "Regularized TF-IDF logistic. C=1.3           0.008045  \n",
       "Regularized TF-IDF logistic. C=1.4           0.007998  \n",
       "Regularized TF-IDF logistic. C=1.5           0.007919  \n",
       "Regularized TF-IDF logistic. C=1.6           0.007854  \n",
       "Regularized TF-IDF logistic. C=1.7           0.007853  \n",
       "Regularized TF-IDF logistic. C=1.8           0.007870  \n",
       "Regularized TF-IDF logistic. C=1.9           0.007865  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_results = results\n",
    "for coef_part in range(1, 20):\n",
    "    coef = float(coef_part)/10\n",
    "    regularized_tfidf = Pipeline([\n",
    "        (\"vectorize\", TfidfVectorizer(analyzer=\"word\", ngram_range=(1, 6))),\n",
    "        (\"model\", LogisticRegression(random_state=seed, C=coef))\n",
    "    ])\n",
    "    coef_results = score_model_oversampling(\n",
    "        \"Regularized TF-IDF logistic. C={0}\".format(coef),\n",
    "        regularized_tfidf,\n",
    "        coef_results,\n",
    "        result_columns,\n",
    "        False\n",
    "    )\n",
    "coef_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "\tAverage: 0.838\n",
      "\tStandard Deviation: 0.001\n",
      "ROC AUC:\n",
      "\tAverage: 0.924\n",
      "\tStandard Deviation: 0.008\n"
     ]
    }
   ],
   "source": [
    "regularized_tfidf_c_1_1 = Pipeline([\n",
    "    (\"vectorize\", TfidfVectorizer(analyzer=\"word\", ngram_range=(1, 6))),\n",
    "    (\"model\", LogisticRegression(random_state=seed, C=1.1))\n",
    "])\n",
    "results = score_model_oversampling(\n",
    "    \"Regularized TF-IDF logistic. C=1.1\",\n",
    "    regularized_tfidf_c_1_1,\n",
    "    results,\n",
    "    result_columns\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hashing Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "\tAverage: 0.772\n",
      "\tStandard Deviation: 0.007\n",
      "ROC AUC:\n",
      "\tAverage: 0.866\n",
      "\tStandard Deviation: 0.007\n"
     ]
    }
   ],
   "source": [
    "hashing_logistic_pipe = Pipeline([\n",
    "    (\"vectorize\", HashingVectorizer()),\n",
    "    (\"model\", LogisticRegression(random_state=seed))])\n",
    "results = score_model_oversampling(\n",
    "    \"Hashing Logistic baseline\",\n",
    "    hashing_logistic_pipe,\n",
    "    results,\n",
    "    result_columns\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### English stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "\tAverage: 0.783\n",
      "\tStandard Deviation: 0.008\n",
      "ROC AUC:\n",
      "\tAverage: 0.871\n",
      "\tStandard Deviation: 0.006\n"
     ]
    }
   ],
   "source": [
    "english_stopwords = stopwords.words(\"english\")\n",
    "nltk_stopwords_hashing_logistic = Pipeline([\n",
    "    (\"vectorize\", HashingVectorizer(stop_words=english_stopwords)),\n",
    "    (\"model\", LogisticRegression(random_state=seed))\n",
    "])\n",
    "results = score_model_oversampling(\n",
    "    \"Hashing NLTK English stopwords logistic\",\n",
    "    nltk_stopwords_hashing_logistic,\n",
    "    results,\n",
    "    result_columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "\tAverage: 0.775\n",
      "\tStandard Deviation: 0.009\n",
      "ROC AUC:\n",
      "\tAverage: 0.866\n",
      "\tStandard Deviation: 0.005\n"
     ]
    }
   ],
   "source": [
    "sklearn_stopwords_hashing_logistic = Pipeline([\n",
    "    (\"vectorize\", HashingVectorizer(stop_words=\"english\")),\n",
    "    (\"model\", LogisticRegression(random_state=seed))\n",
    "])\n",
    "results = score_model_oversampling(\n",
    "    \"Hashing Sklearn English stopwords logistic\",\n",
    "    sklearn_stopwords_hashing_logistic,\n",
    "    results,\n",
    "    result_columns\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Accuracy_std</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>ROC_AUC_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tfidf N-grams (1,6) logistic</th>\n",
       "      <td>0.837519</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.923966</td>\n",
       "      <td>0.008160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regularized TF-IDF logistic. C=0.8</th>\n",
       "      <td>0.836734</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>0.922593</td>\n",
       "      <td>0.008359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count N-grams (1,5) logistic</th>\n",
       "      <td>0.836348</td>\n",
       "      <td>0.009070</td>\n",
       "      <td>0.922453</td>\n",
       "      <td>0.006407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count Logistic</th>\n",
       "      <td>0.817895</td>\n",
       "      <td>0.010648</td>\n",
       "      <td>0.897232</td>\n",
       "      <td>0.009240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count NLTK English stopwords logistic</th>\n",
       "      <td>0.812407</td>\n",
       "      <td>0.008775</td>\n",
       "      <td>0.891127</td>\n",
       "      <td>0.005639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TF-IDF Logistic baseline</th>\n",
       "      <td>0.805341</td>\n",
       "      <td>0.008842</td>\n",
       "      <td>0.894245</td>\n",
       "      <td>0.005339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count Sklearn English stopwords logistic</th>\n",
       "      <td>0.804168</td>\n",
       "      <td>0.009856</td>\n",
       "      <td>0.887977</td>\n",
       "      <td>0.005197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf NLTK English stopwords logistic</th>\n",
       "      <td>0.801015</td>\n",
       "      <td>0.008513</td>\n",
       "      <td>0.884795</td>\n",
       "      <td>0.005838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf Sklearn English stopwords logistic</th>\n",
       "      <td>0.791995</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>0.878878</td>\n",
       "      <td>0.004080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hashing NLTK English stopwords logistic</th>\n",
       "      <td>0.782572</td>\n",
       "      <td>0.008452</td>\n",
       "      <td>0.870553</td>\n",
       "      <td>0.006265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hashing Sklearn English stopwords logistic</th>\n",
       "      <td>0.774733</td>\n",
       "      <td>0.008527</td>\n",
       "      <td>0.865521</td>\n",
       "      <td>0.005346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count Logistic</th>\n",
       "      <td>0.774007</td>\n",
       "      <td>0.022582</td>\n",
       "      <td>0.831514</td>\n",
       "      <td>0.020428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hashing Logistic baseline</th>\n",
       "      <td>0.772374</td>\n",
       "      <td>0.007089</td>\n",
       "      <td>0.865579</td>\n",
       "      <td>0.006791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Accuracy  Accuracy_std   ROC_AUC  \\\n",
       "Tfidf N-grams (1,6) logistic                0.837519      0.000181  0.923966   \n",
       "Regularized TF-IDF logistic. C=0.8          0.836734      0.000664  0.922593   \n",
       "Count N-grams (1,5) logistic                0.836348      0.009070  0.922453   \n",
       "Count Logistic                              0.817895      0.010648  0.897232   \n",
       "Count NLTK English stopwords logistic       0.812407      0.008775  0.891127   \n",
       "TF-IDF Logistic baseline                    0.805341      0.008842  0.894245   \n",
       "Count Sklearn English stopwords logistic    0.804168      0.009856  0.887977   \n",
       "Tfidf NLTK English stopwords logistic       0.801015      0.008513  0.884795   \n",
       "Tfidf Sklearn English stopwords logistic    0.791995      0.002666  0.878878   \n",
       "Hashing NLTK English stopwords logistic     0.782572      0.008452  0.870553   \n",
       "Hashing Sklearn English stopwords logistic  0.774733      0.008527  0.865521   \n",
       "Count Logistic                              0.774007      0.022582  0.831514   \n",
       "Hashing Logistic baseline                   0.772374      0.007089  0.865579   \n",
       "\n",
       "                                            ROC_AUC_std  \n",
       "Tfidf N-grams (1,6) logistic                   0.008160  \n",
       "Regularized TF-IDF logistic. C=0.8             0.008359  \n",
       "Count N-grams (1,5) logistic                   0.006407  \n",
       "Count Logistic                                 0.009240  \n",
       "Count NLTK English stopwords logistic          0.005639  \n",
       "TF-IDF Logistic baseline                       0.005339  \n",
       "Count Sklearn English stopwords logistic       0.005197  \n",
       "Tfidf NLTK English stopwords logistic          0.005838  \n",
       "Tfidf Sklearn English stopwords logistic       0.004080  \n",
       "Hashing NLTK English stopwords logistic        0.006265  \n",
       "Hashing Sklearn English stopwords logistic     0.005346  \n",
       "Count Logistic                                 0.020428  \n",
       "Hashing Logistic baseline                      0.006791  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = results.sort_values(\"Accuracy\", ascending=False)\n",
    "results.to_csv(\"..\\..\\Results\\sentiment_kaggle_results_table.csv\", index=True, index_label=\"Id\")\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В итоге после нескольких сабмитов на kaggle была выбрана следующая модель:\n",
    "\n",
    "1. Оверсемплинг негативных отзывов (548 случайно выбранных примеров)\n",
    "2. Использование N-грамм размером от 1 до 6 слов\n",
    "3. Коэффициент регуляризации 1.1\n",
    "4. Логистическая регрессия.\n",
    "\n",
    "Результат на kaggle: 0.83250, что лучше, чем базовое решение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y\n",
       "0  1\n",
       "1  0\n",
       "2  1\n",
       "3  1\n",
       "4  0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_texts = test_data[\"text\"].tolist()\n",
    "balanced_texts, balanced_classes = balance_data(texts, classes, 548)\n",
    "model = regularized_tfidf_c_1_1.fit(balanced_texts, balanced_classes)\n",
    "result_frame = pd.DataFrame(model.predict(test_texts), columns=[\"y\"])\n",
    "result_frame.to_csv(\"..\\\\..\\\\Results\\\\balanced_tfidf_ng1_6_c_1_1_logistic.csv\", index=True, index_label=\"Id\")\n",
    "result_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
