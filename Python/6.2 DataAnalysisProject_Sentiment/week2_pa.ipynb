{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment: Настройка параметров\n",
    "В этом задании вам предстоит поэкспериментировать с параметрами вашей модели для сентимент-анализа. Все задания выполняются на том же датасете, что и на прошлой неделе.\n",
    "\n",
    "## Инструкции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_result(file_name, result):\n",
    "    file_obj = open(file_name, \"w\")\n",
    "    file_obj.write(result)\n",
    "    file_obj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "negids = movie_reviews.fileids(\"neg\")\n",
    "posids = movie_reviews.fileids(\"pos\")\n",
    "negfeats = [movie_reviews.raw(fileids=[f]) for f in negids]\n",
    "posfeats = [movie_reviews.raw(fileids=[f]) for f in posids]\n",
    "neg_classes = [0] * len(negids)\n",
    "pos_classes = [1] * len(posids)\n",
    "classes = neg_classes + pos_classes\n",
    "all_texts = negfeats + posfeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_columns = [\"Accuracy\"]\n",
    "results_frame = pd.DataFrame(columns=results_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Здесь и далее оценка качества будет выполняться с помощью cross_val_score с cv=5 и остальными параметрами по умолчанию. Оцените среднее качество ( .mean() ) и стандартное отклонение ( .std() ) по fold'ам для: а) pipeline из CountVectorizer() и LogisticRegression(), б) pipeline из TfidfVectorizer() и LogisticRegression(). В соответствующем пункте задания выпишите через пробел среднее в п. а, отклонение в п. а, среднее в п.б и отклонение в п. б"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_count_pipe = Pipeline([(\"vectorize\", CountVectorizer()), (\"model\", LogisticRegression())])\n",
    "logistic_tfidf_pipe = Pipeline([(\"vectorize\", TfidfVectorizer()), (\"model\", LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_score = cross_val_score(logistic_count_pipe, all_texts, classes, cv=cv)\n",
    "tfidf_score = cross_val_score(logistic_tfidf_pipe, all_texts, classes, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.841 0.01677796173556255 0.8210000000000001 0.004062019202317978\n"
     ]
    }
   ],
   "source": [
    "scores_str = \"{0} {1} {2} {3}\".format(\n",
    "    count_score.mean(),\n",
    "    count_score.std(),\n",
    "    tfidf_score.mean(),\n",
    "    tfidf_score.std())\n",
    "write_result(\"scores.txt\", scores_str)\n",
    "results_frame = results_frame.append(pd.DataFrame([\n",
    "    [count_score.mean()],\n",
    "    [tfidf_score.mean()]\n",
    "], index=[\"Count Vectorizer Logistic\", \"Tfidf Vectorizer Logistic\"], columns=results_columns))\n",
    "print(scores_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Попробуйте позадавать параметр min_df у CountVectorizer. Оцените качество вашего классикатора с min_df=10 и с min_df=50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_df_10_count_pipe = Pipeline([(\"vectorize\", CountVectorizer(min_df=10)), (\"model\", LogisticRegression())])\n",
    "min_df_50_count_pipe = Pipeline([(\"vectorize\", CountVectorizer(min_df=50)), (\"model\", LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_df_10_score = cross_val_score(min_df_10_count_pipe, all_texts, classes, cv=cv)\n",
    "min_df_50_score = cross_val_score(min_df_50_count_pipe, all_texts, classes, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8390000000000001 0.813\n"
     ]
    }
   ],
   "source": [
    "min_df_scores = [min_df_10_score.mean(), min_df_50_score.mean()]\n",
    "min_df_scores_str = \"{0} {1}\".format(min_df_scores[0], min_df_scores[1])\n",
    "write_result(\"min_df_scores.txt\", min_df_scores_str)\n",
    "results_frame = results_frame.append(pd.DataFrame(\n",
    "    list(map(lambda score: [score], min_df_scores)),\n",
    "    index=[\"min_df_10 Count Vectorizer Logistic\", \"min_df_50 Count Vectorizer Logistic\"], columns=results_columns))\n",
    "print(min_df_scores_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Поперебирайте классификатор, используемый после CountVectorizer. И vectorizer и классификатор берите с параметрами по умолчанию. Сравните результаты для LogisticRegression, LinearSVC и SGDClassifier. Выпишите в ответе на соответствующий вопрос самое худшее качество из получившихся."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_count_pipe = Pipeline([(\"vectorize\", CountVectorizer()), (\"model\", LinearSVC())])\n",
    "sgd_count_pipe = Pipeline([(\"vectorize\", CountVectorizer()), (\"model\", SGDClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\agasp\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\agasp\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\agasp\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\agasp\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\agasp\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic: 0.841\n",
      "SVM: 0.8325000000000001\n",
      "SGD: 0.7565\n"
     ]
    }
   ],
   "source": [
    "svm_count_score = cross_val_score(svm_count_pipe, all_texts, classes, cv=cv)\n",
    "sgd_count_score = cross_val_score(sgd_count_pipe, all_texts, classes, cv=cv)\n",
    "model_scores = [count_score.mean(), svm_count_score.mean(), sgd_count_score.mean()]\n",
    "write_result(\"min_model_score.txt\", str(min(model_scores)))\n",
    "results_frame = results_frame.append(pd.DataFrame([\n",
    "    [svm_count_score.mean()],\n",
    "    [sgd_count_score.mean()]\n",
    "], index=[\"Count Vectorizer SVM\", \"Count Vectorizer SGD\"], columns=results_columns))\n",
    "print(\"\\n\".join(\n",
    "    map(\n",
    "        lambda mdl: \"{0}: {1}\".format(mdl[0], mdl[1]),\n",
    "        zip(\n",
    "            [\"Logistic\", \"SVM\", \"SGD\"],\n",
    "            model_scores\n",
    "))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Подготовьте список стоп-слов с помощью nltk.corpus.stopwords.words('english'), посмотрите на его элементы, и передайте его в соответствующий параметр CountVectorizer. В sklearn также предусмотрен свой список английских стоп-слов - для этого нужно задать соответствующий параметр равным строке 'english'. Оцените качество классификатора в одном и другом случае и выпишете сначала качество в первом варианте, затем во втором в соответствующем вопросе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download(\"stopwords\")\n",
    "english_stopwords = stopwords.words(\"english\")\n",
    "nltk_stopwords_pipe = Pipeline([\n",
    "    (\"vectorize\", CountVectorizer(stop_words=english_stopwords)),\n",
    "    (\"model\", LogisticRegression())\n",
    "])\n",
    "sklearn_stopwords_pipe = Pipeline([\n",
    "    (\"vectorize\", CountVectorizer(stop_words=\"english\")),\n",
    "    (\"model\", LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nltk: 0.8414999999999999\n",
      "sklearn: 0.8390000000000001\n"
     ]
    }
   ],
   "source": [
    "nltk_stopwords_score = cross_val_score(nltk_stopwords_pipe, all_texts, classes, cv=cv)\n",
    "sklearn_stopwords_score = cross_val_score(sklearn_stopwords_pipe, all_texts, classes, cv=cv)\n",
    "stopwords_scores = [nltk_stopwords_score.mean(), sklearn_stopwords_score.mean()]\n",
    "write_result(\"stopwords_scores.txt\", \" \".join(map(str, stopwords_scores)))\n",
    "results_frame = results_frame.append(pd.DataFrame(\n",
    "    list(map(lambda score: [score], stopwords_scores)),\n",
    "    index=[\"Nltk stopwords Count Vectorizer Logistic\", \"Sklearn stopwords Count Vectorizer Logistic\"],\n",
    "    columns=results_columns))\n",
    "print(\"\\n\".join(map(\n",
    "    lambda model: \"{0}: {1}\".format(model[0], model[1]),\n",
    "    zip(\n",
    "        [\"nltk\", \"sklearn\"],\n",
    "        stopwords_scores)\n",
    ")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.Попробуйте в CountVectorizer добавить к словам биграммы и измерить качество модели. А затем постройте модель на частотах буквенных n-грамм c n от 3 до 5, указав соответствующее значение параметра ngram_range и параметр analyzer='char_wb'. Полученные два числа запишите через пробел в ответе на соответствующий вопрос."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_pipe = Pipeline([\n",
    "    (\"vectorize\", CountVectorizer(analyzer=\"word\")),\n",
    "    (\"model\", LogisticRegression())\n",
    "])\n",
    "bigram_score = cross_val_score(bigram_pipe, all_texts, classes, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_range_pipe = Pipeline([\n",
    "    (\"vectorize\", CountVectorizer(analyzer=\"char_wb\", ngram_range=(3, 5))),\n",
    "    (\"model\", LogisticRegression())\n",
    "])\n",
    "ngram_range_score = cross_val_score(ngram_range_pipe, all_texts, classes, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram: 0.841\n",
      "Ngram (3,5): 0.819\n"
     ]
    }
   ],
   "source": [
    "ngram_scores = list(map(lambda scores: scores.mean(), [bigram_score, ngram_range_score]))\n",
    "write_result(\"ngram_scores.txt\", \" \".join(map(str, ngram_scores)))\n",
    "results_frame = results_frame.append(pd.DataFrame(\n",
    "    list(map(lambda score: [score], ngram_scores)),\n",
    "    index=[\"Bigrams Count Vectorizer Logistic\", \"Ngrams (3,5) Count Vectorizer Logistic\"],\n",
    "    columns=results_columns))\n",
    "print(\"\\n\".join(\n",
    "    map(\n",
    "        lambda model: \"{0}: {1}\".format(model[0], model[1]),\n",
    "        zip(\n",
    "            [\"Bigram\", \"Ngram (3,5)\"],\n",
    "            ngram_scores))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Nltk stopwords Count Vectorizer Logistic</th>\n",
       "      <td>0.8415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count Vectorizer Logistic</th>\n",
       "      <td>0.8410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bigrams Count Vectorizer Logistic</th>\n",
       "      <td>0.8410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_df_10 Count Vectorizer Logistic</th>\n",
       "      <td>0.8390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sklearn stopwords Count Vectorizer Logistic</th>\n",
       "      <td>0.8390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count Vectorizer SVM</th>\n",
       "      <td>0.8325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tfidf Vectorizer Logistic</th>\n",
       "      <td>0.8210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ngrams (3,5) Count Vectorizer Logistic</th>\n",
       "      <td>0.8190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_df_50 Count Vectorizer Logistic</th>\n",
       "      <td>0.8130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count Vectorizer SGD</th>\n",
       "      <td>0.7565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Accuracy\n",
       "Nltk stopwords Count Vectorizer Logistic       0.8415\n",
       "Count Vectorizer Logistic                      0.8410\n",
       "Bigrams Count Vectorizer Logistic              0.8410\n",
       "min_df_10 Count Vectorizer Logistic            0.8390\n",
       "Sklearn stopwords Count Vectorizer Logistic    0.8390\n",
       "Count Vectorizer SVM                           0.8325\n",
       "Tfidf Vectorizer Logistic                      0.8210\n",
       "Ngrams (3,5) Count Vectorizer Logistic         0.8190\n",
       "min_df_50 Count Vectorizer Logistic            0.8130\n",
       "Count Vectorizer SGD                           0.7565"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_frame.sort_values(results_columns, ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
