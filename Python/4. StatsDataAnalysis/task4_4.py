
# В этом задании вам предлагается проанализировать данные одной из американских телекоммуникационных компаний о
# пользователях, которые потенциально могут уйти.
#%%
import pandas as pd
import numpy as np

frame = pd.read_csv("..\..\Data\churn_analysis.csv", sep=",", header=0)
frame.head()
# Измерены следующие признаки:
#    state — штат США
#    account_length — длительность использования аккаунта
#    area_code — деление пользователей на псевдорегионы, использующееся в телекоме
#    intl_plan — подключена ли у пользователя услуга международного общения
#    vmail_plan — подключена ли у пользователя услуга голосовых сообщений
#    vmail_message — количество голосых сообщений, который пользователь отправил / принял
#    day_calls — сколько пользователь совершил дневных звонков
#    day_mins — сколько пользователь проговорил минут в течение дня
#    day_charge — сколько пользователь заплатил за свою дневную активность
#    eve_calls, eve_mins, eve_charge — аналогичные метрики относительно вечерней активности
#    night_calls, night_mins, night_charge — аналогичные метрики относительно ночной активности
#    intl_calls, intl_mins, intl_charge — аналогичные метрики относительно международного общения
#    custserv_calls — сколько раз пользователь позвонил в службу поддержки
#    treatment — номер стратегии, которая применялись для удержания абонентов (0, 2 = два разных типа воздействия, 1 = контрольная группа)
#    mes_estim — оценка интенсивности пользования интернет мессенджерами
#    churn — результат оттока: перестал ли абонент пользоваться услугами оператора
# Давайте рассмотрим всех пользователей из контрольной группы (treatment = 1). Для таких пользователей мы хотим
# проверить гипотезу о том, что штат абонента не влияет на то, перестанет ли абонент пользоваться услугами оператора.
# Для этого мы воспользуемся критерием хи-квадрат.
#  Постройте таблицы сопряженности между каждой из всех 1275 возможных неупорядоченных пар штатов и значением признака churn.
#  Для каждой такой таблицы 2x2 применить критерий хи-квадрат можно с помощью функции
#    scipy.stats.chi2_contingency(subtable, correction=False)
# Заметьте, что, например, (AZ, HI) и (HI, AZ) — это одна и та же пара.
# Обязательно выставьте correction=False (о том, что это значит, вы узнаете из следующих вопросов).
# Сколько достигаемых уровней значимости оказались меньше, чем α=0.05?
#%%
control_group = frame[frame["treatment"] == 1]
states = list(set(control_group["state"].values))
control_states_pivot = pd.pivot_table(control_group, values=["treatment"], index=["state"], columns=["churn"], fill_value = 0, aggfunc='count')
control_states_pivot
#%%
not_enough_data_count = len(filter(lambda val: val < 5, control_states_pivot.loc[:,[False, True]].values))
not_enough_data_count += len(filter(lambda val: val < 5, control_states_pivot.loc[:,[True, False]].values))
print "Count of cells where is not enough data is %i. The percent of these cells is %.2f%%" % (not_enough_data_count, float(not_enough_data_count)/(control_states_pivot.shape[0]*control_states_pivot.shape[1])*100)
#%%
from scipy import stats
def calculate_pairwise_diffs(pivot_table, states, stat_calculator):
    states_count = len(states)
    result = []
    for i in xrange(states_count-1):
        first_state = states[i]
        for j in xrange(i+1, states_count):
            second_state = states[j]
            chi_2_stat = stat_calculator(pivot_table.loc[[first_state,second_state],:])
            result.append(chi_2_stat)
    return result
#%%
def chi_2_stat_no_correction(table):
    return stats.chi2_contingency(table, correction=False)
chi_2_stats = calculate_pairwise_diffs(control_states_pivot, states, chi_2_stat_no_correction)
print "A number of cells where p-value is less than 0.05 for chi-square criterion: %i" % len(filter(lambda stat: stat[1] < 0.05, chi_2_stats))
# Какие проблемы Вы видите в построении анализа из первого вопроса? Отметьте все верные утверждения. 
#    Интерпретация числа достигаемых уровней значимости, меньших α=0.05, некорректна, поскольку не сделана поправка
#      на множественную проверку гипотез.
#    Применение критерия xи-квадрат для этих данных не обосновано, потому что не выполняются условия, при которых этот
#      критерий дает правильные результаты.


# В основе критерия xи-квадрат лежит предположение о том, что если верна нулевая гипотеза, то дискретное биномиальное
# распределение данных по клеткам в таблице сопряженности может быть аппроксимировано с помощью непрерывного распределения
# xи-квадрат. Однако точность такой аппроксимации существенно зависит от суммарного количества наблюдений и их
# распределения в этой таблице (отсюда и ограничения при использовании критерия xи-квадрат).
# Одним из способов коррекции точности аппроксимации является поправка Йетса на непрерывность. Эта поправка заключается
# в вычитании константы 0.5 из каждого модуля разности наблюденного Oi и ожидаемого Ei значений, то есть, статистика
# с такой поправкой выглядит так: 
#    χ^2Yates=∑{i=1->N}(|Oi−Ei|−0.5)^2/Ei
# Такая поправка, как несложно догадаться по формуле, как правило, уменьшает значение статистики χ^2, то есть
# увеличивает достигаемый уровень значимости.
# Эта поправка обычно используется для таблиц сопряженности размером 2x2 и для небольшого количества наблюдений.
# Такая поправка, однако, не является серебрянной пулей, и часто критикуется за то, что статистический критерий при
# ее использовании становится слишком консервативным, то есть часто не отвергает нулевую гипотезу там, где она
# неверна (совершает ошибку II рода).
# Полезно знать, что эта поправка часто включена по умолчанию (например, в функции scipy.stats.chi2_contingency) и
# понимать ее влияние на оценку достигаемого уровня значимости.
# Проведите те же самые сравнения, что и в вопросе №1, только с включенной коррекцией
#    scipy.stats.chi2_contingency(subtable, correction=True)
# и сравните полученные результаты, отметив все верные варианты.
#%%
def chi_2_stat_correction(table):
    return stats.chi2_contingency(table, correction=True)
chi_2_corrected_stats = calculate_pairwise_diffs(control_states_pivot, states, chi_2_stat_correction)
print "A number of cells where p-value is less than 0.05 for chi-square criterion with correction: %i" % len(filter(lambda stat: stat[1] < 0.05, chi_2_corrected_stats))
#    Количество достигаемых уровней значимости, меньших, чем 0.05, в точности равно нулю. То есть поправка увеличила
#      достигаемые уровни значимости настолько, что больше ни одно из значений достигаемого уровня значимости не
#      попадает в диапазон от 0 до 0.05.
corrected_stats_greater_count = len(filter(lambda(stat, corrected): corrected[1] > stat[1], zip(chi_2_stats, chi_2_corrected_stats)))
corrected_stats_less_count = len(filter(lambda(stat, corrected): corrected[1] < stat[1], zip(chi_2_stats, chi_2_corrected_stats)))
print "A number of corrected stats where p-value is greater than p-value without correction is %i. Percentage: %.2f" % (corrected_stats_greater_count, float(corrected_stats_greater_count)/len(chi_2_stats)*100)
print "A number of corrected stats where p-value is less than p-value without correction is %i. Percentage: %.2f" % (corrected_stats_less_count, float(corrected_stats_less_count)/len(chi_2_stats)*100)
#    Достигаемые уровни значимости на наших данных, полученные с помощью критерия xи-квадрат с поправкой Йетса, в
#      среднем получаются больше, чем соответствующие значения без поправки.


# Что если у нас мало данных, мы не хотим использовать аппроксимацию дискретного распределения непрерывным и
# использовать сомнительную поправку, предположения критерия xи-квадрат не выполняются, а проверить гипотезу о том,
# что данные принадлежат одному распределению, нужно?
# В таком случае прибегают к так называемому точному критерию Фишера. Этот критерий не использует приближений и в
# точности вычисляет значение достигаемого уровня значимости используя комбинаторный подход.
# Пусть у нас есть таблица сопряженности 2x2:
#                  Группа 1    Группа 2    Σ
# Воздействие 1           a           b    a+b
# Воздействие 2           c           d    c+d
#             Σ         a+c         b+d    n=a+b+c+d
# Тогда вероятность получить именно такие a,b,c,d при фиксированных значениях сумм по строкам и по столбцам) задается
# выражением
#    p=(a+b)!(c+d)!(a+c)!(b+d)!/(a! b! c! d! n!)
# В числителе этой дроби стоит суммарное количество способов выбрать a и c из a+b и c+d соответственно.
# А в знаменателе — количество способов выбрать число объектов, равное сумме элементов первого столбца a+c из общего
# количества рассматриваемых объектов n.
# Чтобы посчитать достигаемый уровень значимости критерия Фишера, нужно перебрать все возможные значения a,b,c,d, в
# клетках этой таблицы так, чтобы построковые и постолбцовые суммы не изменились. Для каждого такого набора a,b,c,d 
# нужно вычислить значение pi по формуле выше и просуммировать все такие значения pi, которые меньше или равны p,
# которое мы вычислили по наблюдаемым значениям a,b,c,d.
# Понятно, что такой критерий вычислительно неудобен в силу большого количества факториалов в формуле выше. То есть
# даже при небольших выборках для вычисления значения этого критерия приходится оперировать очень большими числами.
# Поэтому данным критерием пользуются обычно только для таблиц 2x2, но сам критерий никак не ограничен количеством
# строк и столбцов, и его можно построить для любой таблицы n×m.
# Посчитайте для каждой пары штатов, как и в первом задании, достигаемый уровень значимости с помощью точного критерия
# Фишера и сравните получившиеся значения с двумя другими подходами, описанными выше.
# Точный критерий Фишера удобно вычислять с помощью функции
#     scipy.stats.fisher_exact
# которая принимает на вход таблицу сопряженности 2x2.
#%%
def fisher_exact_stat(table):
    return stats.fisher_exact(table, alternative="two-sided")
fischer_stats = calculate_pairwise_diffs(control_states_pivot, states, fisher_exact_stat)
fischer_stats_greater_count_c = len(filter(lambda(corrected, fischer): fischer[1] > corrected[1], zip(chi_2_corrected_stats, fischer_stats)))
fischer_stats_less_count_c = len(filter(lambda(corrected, fischer): fischer[1] < corrected[1], zip(chi_2_corrected_stats, fischer_stats)))
fischer_stats_greater_count = len(filter(lambda(stat, fischer): fischer[1] > stat[1], zip(chi_2_stats, fischer_stats)))
fischer_stats_less_count = len(filter(lambda(stat, fischer): fischer[1] < stat[1], zip(chi_2_stats, fischer_stats)))
print "A number of cells where p-value is less than 0.05 for Fischer criterion: %i" % len(filter(lambda stat: stat[1] < 0.05, fisher_stats))
print "A number of Fischer stats where p-value is greater than p-value chi-square with correction is %i. Percentage: %.2f" % (fischer_stats_greater_count_c, float(fischer_stats_greater_count_c)/len(fisher_stats)*100)
print "A number of Fischer stats where p-value is less than p-value chi-square with correction is %i. Percentage: %.2f" % (fischer_stats_less_count_c, float(fischer_stats_less_count_c)/len(fisher_stats)*100)
print "A number of Fischer stats where p-value is greater than p-value chi-square is %i. Percentage: %.2f" % (fischer_stats_greater_count, float(fischer_stats_greater_count)/len(fisher_stats)*100)
print "A number of Fischer stats where p-value is less than p-value chi-square is %i. Percentage: %.2f" % (fischer_stats_less_count, float(fischer_stats_less_count)/len(fisher_stats)*100)
#    Точный критерий Фишера на наших данных дает значения достигаемого уровня значимости в среднем значительно большие,
#      чем xи-квадрат без поправки
#    Точный критерий Фишера точно также, как и критерий xи-квадрат, нельзя использовать, если наблюдений < 40 и если
#      ожидаемое значение меньше 5 больше чем в 20% ячейках.
#    Точный критерий Фишера на наших данных дает значения достигаемого уровня значимости в среднем меньшие, чем
#      xи-квадрат с поправкой Йетса
#    Точный критерий Фишера всегда лучше, чем критерий xи-квадрат, потому что не использует аппроксимацию дискретного
#      распределения непрерывным. Однако при увеличении размера выборки его преимущества по сравнению с критерем
#      xи-квадрат уменьшаются, в пределе достигая нуля.
#    Точный критерий Фишера на наших данных дает значения достигаемого уровня значимости в среднем меньшие, чем
#      xи-квадрат без поправки
#    Точный критерий Фишера на наших данных дает значения достигаемого уровня значимости в среднем большие, чем
#      xи-квадрат с поправкой Йетса

# Давайте попробуем применить полученные знания о разных видах корреляции и ее применимости на практике.
# Рассмотрим пару признаков day_calls и mes_estim. Посчитайте корреляцию Пирсона между этими признаками на всех
# данных, ее значимость.
# Отметьте все верные утверждения.
#    Корреляция Пирсона имеет положительный знак, и отличие корреляции от нуля на уровне доверия 0.05 значимо.
#    Корреляция Пирсона имеет положительный знак, и отличие корреляции от нуля на уровне доверия 0.05 не значимо. 
#    Все варианты неверны, потому что значимость корреляции Пирсона можно оценивать только для нормального
#      распределения, как и упоминалось в лекциях.
#    Корреляция Пирсона имеет отрицательный знак, и отличие корреляции от нуля на уровне доверия 0.05 значимо.
#    Корреляция Пирсона имеет отрицательный знак, и отличие корреляции от нуля на уровне доверия 0.05 не значимо.


# Еще раз рассмотрим пару признаков day_calls и mes_estim. Посчитайте корреляцию Спирмена между этими признаками на
# всех данных, ее значимость.
# Отметьте все верные утверждения.
#    Корреляция Спирмена имеет положительный знак, и отличие корреляции от нуля на уровне доверия 0.05 не значимо.
#    Корреляция Спирмена имеет положительный знак, и отличие корреляции от нуля на уровне доверия 0.05 значимо.
#    Корреляция Спирмена имеет отрицательный знак, и отличие корреляции от нуля на уровне доверия 0.05 значимо.
#    Корреляция Спирмена тут неприменима, поскольку речь идет о непрерывных величинах, а корреляция Спирмена
#      применяется к выборочным рангам двух выборок.
#    Корреляция Спирмена имеет отрицательный знак, и отличие корреляции от нуля на уровне доверия 0.05 не значимо.


# Как можно интерпретировать полученные значения коэффициентов корреляции и достигаемые уровни значимости при проверки
# гипотез о равенстве нулю этих коэффициентов?
#    Не стоит ориентироваться на значение корреляции Спирмена, потому что корреляцию Спирмена можно считать только
#      тогда, когда оба признака дискретные и между значениями можно установить строгий порядок.
#    Предположение нормальности данных двух признаков не выполнено, что хорошо видно на ку-ку графике, поэтому
#      корреляция Пирсона может быть полностью неадекватна.
#    Посчитанные корреляции и их значимости говорят лишь о том, что необходимо взглянуть на данные глазами и
#      попытаться понять, что приводит к таким (противоречивым?) результатам.
#    Подсчет корреляций не имеет особого смысла, поскольку корреляция ничего не говорит о том, какая на самом деле
#      зависимость имеется между признаками.


# Посчитайте значение коэффицента корреляции Крамера между двумя признаками: штатом (state) и оттоком пользователей
# (churn) для всех пользователей, которые находились в контрольной группе (treatment=1). Что можно сказать о
# достигаемом уровне значимости при проверке гипотезы о равенство нулю этого коэффициента?
#    Достигаемый уровень значимости < 0.05, то есть, отличие от нуля значения коэффицента Крамера значимо.
#    Достигаемый уровень значимости > 0.05, то есть, отличие от нуля значения коэффицента Крамера незначимо.
#    Для вычисления коэффициента Крамера используется значение статистики xи-квадрат, на которую мы не можем
#      положиться применительно к нашим данным.
#    Коэффициент корреляции Крамера не может быть использован для сравнения связи этих двух признаков, потому что он
#      используется для таблиц сопряженности, где каждая из размерностей больше двух. Если хотя бы одна из
#      размерностей равна 2, то нужно использовать коэффициент корреляции Мэтьюса.


# Вы прослушали большой курс и к текущему моменту обладете достаточными знаниями, чтобы попытаться самостоятельно
# выбрать нужный метод/инструмент/статистический критерий и сделать правильное заключение.
# В этой части задания вам нужно будет самостоятельно решить, с помощью каких методов можно провести анализ
# эффективности удержания (churn) с помощью раличных методов (treatment = 0, treatment = 2) относительно контрольной
# группы пользователей (treatment = 1).
# Что можно сказать об этих двух методах (treatment = 0, treatment = 2)? Одинаковы ли они с точки зрения эффективности?
# Каким бы методом вы бы посоветовали воспользоваться компании?
# Не забудьте про поправку на множественную проверку! И не пользуйтесь односторонними альтернативами, поскольку вы не
# знаете, к каким действительно последствиям приводят тестируемые методы (treatment = 0, treatment = 2)!
#    Ни один из методов не показал значительного улучшения относительно других, о чем говорит групповой статистический
#      критерий. 
#    treatment = 0 статистически значимо отличается от контрольной группы treatment = 1
#    treatment = 2 статистически значимо отличается от контрольной группы treatment = 1
#    В дальнейшем телеком компании рекомендуется использовать и treatment = 0, и treatment = 2 для наибольшей
#      эффективности удержения абонентов.
#    Отличие между treatment = 0 и treatment = 2 относительно влияния на уровень churn статистически незначимо.
