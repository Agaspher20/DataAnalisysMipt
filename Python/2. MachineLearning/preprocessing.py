## Предобработка данных и логистическая регрессия для задачи бинарной классификации

### Programming assignment
# В задании вам будет предложено ознакомиться с основными техниками предобработки данных, а так же применить их
# для обучения модели логистической регрессии. Ответ потребуется загрузить в соответствующую форму в виде 6
# текстовых файлов.
# Для выполнения задания требуется Python версии 2.7, а также актуальные версии библиотек:
# NumPy: 1.10.4 и выше
# Pandas: 0.17.1 и выше
# Scikit-learn: 0.17 и выше

#%%
import pandas as pd
import numpy as np
import matplotlib
from matplotlib import pyplot as plt
matplotlib.style.use('ggplot')
%matplotlib inline

### Описание датасета
# Задача: по 38 признакам, связанных с заявкой на грант (область исследований учёных, информация по их
# академическому бэкграунду, размер гранта, область, в которой он выдаётся) предсказать, будет ли заявка
# принята. Датасет включает в себя информацию по 6000 заявкам на гранты, которые были поданы в университете
# Мельбурна в период с 2004 по 2008 год.
# Полную версию данных с большим количеством признаков можно найти на https://www.kaggle.com/c/unimelb.

#%%
data = pd.read_csv('preprocessing_data.csv')
data.shape

# Выделим из датасета целевую переменную Grant.Status и обозначим её за y Теперь X обозначает обучающую выборку,
# y - ответы на ней
#%%
X = data.drop('Grant.Status', 1)
y = data['Grant.Status']

## Логистическая регрессия

### Предобработка данных
# Из свойств данной модели следует, что:
# все X должны быть числовыми данными (в случае наличия среди них категорий, их требуется некоторым способом
# преобразовать в вещественные числа)
# среди X не должно быть пропущенных значений (т.е. все пропущенные значения перед применением модели следует
# каким-то образом заполнить)
# Поэтому базовым этапом в предобработке любого датасета для логистической регрессии будет кодирование
# категориальных признаков, а так же удаление или интерпретация пропущенных значений
# (при наличии того или другого).
#%%
data.head()

# Видно, что в датасете есть как числовые, так и категориальные признаки. Получим списки их названий:
#%%
numeric_cols = ['RFCD.Percentage.1', 'RFCD.Percentage.2', 'RFCD.Percentage.3', 
                'RFCD.Percentage.4', 'RFCD.Percentage.5',
                'SEO.Percentage.1', 'SEO.Percentage.2', 'SEO.Percentage.3',
                'SEO.Percentage.4', 'SEO.Percentage.5',
                'Year.of.Birth.1', 'Number.of.Successful.Grant.1', 'Number.of.Unsuccessful.Grant.1']
categorical_cols = list(set(X.columns.values.tolist()) - set(numeric_cols))

# Также в нём присутствуют пропущенные значения. Очевидным решением будет исключение всех данных, у которых
# пропущено хотя бы одно значение. Сделаем это:
#%%
data.dropna().shape

# Видно, что тогда мы выбросим почти все данные, и такой метод решения в данном случае не сработает.
# Пропущенные значения можно так же интерпретировать, для этого существует несколько способов, они различаются
# для категориальных и вещественных признаков.

# Для вещественных признаков:
#    заменить на 0 (данный признак давать вклад в предсказание для данного объекта не будет)
#    заменить на среднее (каждый пропущенный признак будет давать такой же вклад, как и среднее значение
#      признака на датасете)

# Для категориальных:
#    интерпретировать пропущенное значение, как ещё одну категорию (данный способ является самым естественным,
#      так как в случае категорий у нас есть уникальная возможность не потерять информацию о наличии пропущенных
#      значений; обратите внимание, что в случае вещественных признаков данная информация неизбежно теряется)

## Задание 0. Обработка пропущенных значений.
# Заполните пропущенные вещественные значения в X нулями и средними по столбцам, назовите полученные датафреймы
# X_real_zeros и X_real_mean соответственно. Для подсчёта средних используйте описанную ниже функцию
# calculate_means, которой требуется передать на вход вешественные признаки из исходного датафрейма.

# Все категориальные признаки в X преобразуйте в строки, пропущенные значения требуется также преобразовать
# в какие-либо строки, которые не являются категориями (например, 'NA'), полученный датафрейм назовите X_cat.
# Для объединения выборок здесь и далее в задании рекомендуется использовать функции
# np.hstack(...)
# np.vstack(...)
#%%
def calculate_means(numeric_data):
    means = np.zeros(numeric_data.shape[1])
    for j in xrange(numeric_data.shape[1]):
        to_sum = numeric_data.iloc[:,j]
        indices = np.nonzero(~numeric_data.iloc[:,j].isnull())[0]
        correction = np.amax(to_sum[indices])
        to_sum /= correction
        mean = 0
        for i in indices:
            mean += to_sum[i]
        mean /= indices.size
        mean *= correction
        means[j] = mean
    return pd.Series(means, numeric_data.columns)

#%%
numeric_data = X[numeric_cols]
numeric_means = calculate_means(numeric_data)
X_real_zeros = np.zeros(numeric_data.shape)
X_real_mean = np.zeros(numeric_data.shape)

#%%
for i in xrange(numeric_data.shape[0]):
    for j in xrange(numeric_data.shape[1]):
        numeric_value = numeric_data.iloc[i,j]
        X_real_zeros[i,j] = 0 if np.isnan(numeric_value) else numeric_value
        X_real_mean[i,j] = numeric_means[j] if np.isnan(numeric_value) else numeric_value

#%%
X_real_zeros = pd.DataFrame(X_real_zeros, columns=numeric_data.columns)
X_real_mean = pd.DataFrame(X_real_mean, columns=numeric_data.columns)

#%%
categorical_data = X[categorical_cols]
categorical_values = np.empty(categorical_data.shape, dtype='|S10')

#%%
for i in xrange(categorical_data.shape[0]):
    for j in xrange(categorical_data.shape[1]):
        categorical_values[i,j] = str(categorical_data.iloc[i,j])

#%%
categorical_data = pd.DataFrame(categorical_values, columns=categorical_data.columns)

#%%
categorical_data.head(2)

## Преобразование категориальных признаков.
# В предыдущей ячейке мы разделили наш датасет ещё на две части: в одной присутствуют только вещественные
# признаки, в другой только категориальные. Это понадобится нам для раздельной последующей обработки этих
# данных, а так же для сравнения качества работы тех или иных методов.
# Для использования модели регрессии требуется преобразовать категориальные признаки в вещественные.
# Рассмотрим основной способ преоборазования категориальных признаков в вещественные: one-hot encoding.
# Его идея заключается в том, что мы преобразуем категориальный признак при помощи бинарного кода:
# каждой категории ставим в соответствие набор из нулей и единиц.
# Посмотрим, как данный метод работает на простом наборе данных.
#%%
from sklearn.linear_model import LogisticRegression as LR
from sklearn.feature_extraction import DictVectorizer as DV
#%%
categorial_data = pd.DataFrame({'sex': ['male', 'female', 'male', 'female'], 
                                'nationality': ['American', 'European', 'Asian', 'European']})
print('Исходные данные:\n')
print(categorial_data)
encoder = DV(sparse = False)
encoded_data = encoder.fit_transform(categorial_data.T.to_dict().values())
print('\nЗакодированные данные:\n')
print(encoded_data)

# Как видно, в первые три колонки оказалась закодированна информация о стране, а во вторые две - о поле.
# При этом для совпадающих элементов выборки строки будут полностью совпадать. Также из примера видно,
# что кодирование признаков сильно увеличивает их количество, но полностью сохраняет информацию, в том числе
# о наличии пропущенных значений (их наличие просто становится одним из бинарных признаков в преобразованных
# данных).
# Теперь применим one-hot encoding к категориальным признакам из исходного датасета. Обратите внимание на
# общий для всех методов преобработки данных интерфейс. Функция
# encoder.fit_transform(X)
# позволяет вычислить необходимые параметры преобразования, впоследствии к новым данным можно уже применять
# функцию
# encoder.transform(X)
# Очень важно применять одинаковое преобразование как к обучающим, так и тестовым данным, потому что в
# противном случае вы получите непредсказуемые, и, скорее всего, плохие результаты. В частности, если вы
# отдельно закодируете обучающую и тестовую выборку, то получите вообще говоря разные коды для одних и тех
# же признаков, и ваше решение работать не будет.
# Также параметры многих преобразований (например, рассмотренное ниже масштабирование) нельзя вычислять
# одновременно на данных из обучения и теста, потому что иначе подсчитанные на тесте метрики качества будут
# давать смещённые оценки на качество работы алгоритма. Кодирование категориальных признаков не считает на
# обучающей выборке никаких параметров, поэтому его можно применять сразу к всему датасету.

#%%
encoder = DV(sparse = False)
X_cat_oh = encoder.fit_transform(categorical_data.T.to_dict().values())
X_cat_oh = pd.DataFrame(X_cat_oh)

# Для построения метрики качества по результату обучения требуется разделить исходный датасет на обучающую
# и тестовую выборки.
# Обращаем внимание на заданный параметр для генератора случайных чисел: random_state. Так как результаты на
# обучении и тесте будут зависеть от того, как именно вы разделите объекты, то предлагается использовать
# заранее определённое значение для получение результатов, согласованных с ответами в системе проверки заданий.
#%%
from sklearn.cross_validation import train_test_split

(X_train_real_zeros, 
 X_test_real_zeros, 
 y_train, y_test) = train_test_split(X_real_zeros, y, 
                                     test_size=0.3, 
                                     random_state=0)
(X_train_real_mean, 
 X_test_real_mean) = train_test_split(X_real_mean, 
                                      test_size=0.3, 
                                      random_state=0)
(X_train_cat_oh,
 X_test_cat_oh) = train_test_split(X_cat_oh, 
                                   test_size=0.3, 
                                   random_state=0)

## Описание классов
# Итак, мы получили первые наборы данных, для которых выполнены оба ограничения логистической регрессии на
# входные данные. Обучим на них регрессию, используя имеющийся в библиотеке sklearn функционал по подбору
# гиперпараметров модели
# optimizer = GridSearchCV(estimator, param_grid)
# где:
# estimator - обучающий алгоритм, для которого будет производиться подбор параметров
# param_grid - словарь параметров, ключами которого являются строки-названия, которые передаются алгоритму
#              estimator, а значения - набор параметров для перебора
# Данный класс выполняет кросс-валидацию обучающей выборки для каждого набора параметров и находит те,
# на которых алгоритм работает лучше всего. Этот метод позволяет настраивать гиперпараметры по обучающей
# выборке, избегая переобучения. Некоторые опциональные параметры вызова данного класса, которые нам
# понадобятся:
# scoring - функционал качества, максимум которого ищется кросс валидацией, по умолчанию используется функция
# score() класса esimator
# n_jobs - позволяет ускорить кросс-валидацию, выполняя её параллельно, число определяет количество
# одновременно запущенных задач
# cv - количество фолдов, на которые разбивается выборка при кросс-валидации
# После инициализации класса GridSearchCV, процесс подбора параметров запускается следующим методом:
# optimizer.fit(X, y)
# На выходе для получения предсказаний можно пользоваться функцией
# optimizer.predict(X)
# для меток или
# optimizer.predict_proba(X)
# для вероятностей (в случае использования логистической регрессии).
# Также можно напрямую получить оптимальный класс estimator и оптимальные параметры, так как они является
# атрибутами класса GridSearchCV:
# best_estimator_ - лучший алгоритм
# best_params_ - лучший набор параметров
# Класс логистической регрессии выглядит следующим образом:
# estimator = LogisticRegression(penalty)
# где penalty принимает либо значение 'l2', либо 'l1'. По умолчанию устанавливается значение 'l2', и везде в
# задании, если об этом не оговорено особо, предполагается использование логистической регрессии с
# L2-регуляризацией.

## Задание 1. Сравнение способов заполнения вещественных пропущенных значений.
# 1. Составьте две обучающие выборки из вещественных и категориальных признаков: в одной вещественные признаки,
#    где пропущенные значения заполнены нулями, в другой - средними. Рекомендуется записывать в выборки сначала
#    вещественные, а потом категориальные признаки.
#%%
X_train_zero_cat = np.hstack((X_train_real_zeros,X_train_cat_oh))
X_test_zero_cat = np.hstack((X_test_real_zeros,X_test_cat_oh))
X_train_mean_cat = np.hstack((X_train_real_mean,X_train_cat_oh))
X_test_mean_cat = np.hstack((X_test_real_mean,X_test_cat_oh))

# 2. Обучите на них логистическую регрессию, подбирая параметры из заданной сетки param_grid по методу
#    кросс-валидации с числом фолдов cv=3. В качестве оптимизируемой функции используйте заданную по умолчанию.
#%%
from sklearn.linear_model import LogisticRegression
from sklearn.grid_search import GridSearchCV
from sklearn.metrics import roc_auc_score
#%%
optimizer_zero = LogisticRegression('l2')
optimizer_mean = LogisticRegression('l2')
print optimizer_mean.get_params().keys()
#%%
param_grid = {'C': [0.01, 0.05, 0.1, 0.5, 1, 5, 10]}
cv = 3
estimator_zero = GridSearchCV(optimizer_zero, param_grid, cv=cv)
estimator_mean = GridSearchCV(optimizer_mean, param_grid, cv=cv)
#%%
estimator_zero.fit(X_train_zero_cat, y_train)
best_zero_optimizer = estimator_zero.best_estimator_
best_zero_params = estimator_zero.best_params_
best_zero_params
#%%
estimator_mean.fit(X_train_mean_cat, y_train)
best_mean_optimizer = estimator_mean.best_estimator_
best_mean_params = estimator_mean.best_params_
best_mean_params

# 3. Постройте два графика оценок точности +- их стандратного отклонения в зависимости от гиперпараметра и
#    убедитесь, что вы действительно нашли её максимум. Также обратите внимание на большую дисперсию
#    получаемых оценок (уменьшить её можно увеличением числа фолдов cv).
#%%
def plot_scores(optimizer):
    scores = [[item[0]['C'], 
               item[1], 
               (np.sum((item[2]-item[1])**2)/(item[2].size-1))**0.5] for item in optimizer.grid_scores_]
    scores = np.array(scores)
    plt.semilogx(scores[:,0], scores[:,1])
    plt.fill_between(scores[:,0], scores[:,1]-scores[:,2], 
                                  scores[:,1]+scores[:,2], alpha=0.3)
    plt.show()
#%%
print "zero"
plot_scores(estimator_zero)
#%%
print "mean"
plot_scores(estimator_mean)
# 4. Получите две метрики качества AUC ROC на тестовой выборке и сравните их между собой. Какой способ
#    заполнения пропущенных вещественных значений работает лучше? В дальнейшем для выполнения задания в
#    качестве вещественных признаков используйте ту выборку, которая даёт лучшее качество на тесте.
#%%
zero_roc_auc = roc_auc_score(y_test, estimator_zero.predict(X_test_zero_cat))
mean_roc_auc = roc_auc_score(y_test, estimator_mean.predict(X_test_mean_cat))
print zero_roc_auc, mean_roc_auc
# 5. Передайте два значения AUC ROC (сначала для выборки, заполненной средними, потом для выборки,
#    заполненной нулями) в функцию write_answer_1 и запустите её. Полученный файл является ответом на 1 задание.
#%%
def write_answer_1(auc_1, auc_2):
    auc = (auc_1 + auc_2)/2
    with open("preprocessing_lr_answer1.txt", "w") as fout:
        fout.write(str(auc))
#%%
write_answer_1(mean_roc_auc,zero_roc_auc)
# 6. Информация для интересующихся: вообще говоря, не вполне логично оптимизировать на кросс-валидации заданный
#    по умолчанию в классе логистической регрессии функционал accuracy, а измерять на тесте AUC ROC, но это,
#    как и ограничение размера выборки, сделано для ускорения работы процесса кросс-валидации.
