{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peer-graded Assignment: Эксперименты с моделью\n",
    "\n",
    "На прошлой неделе вы поучаствовали в соревновании на kaggle и, наверняка, большинство успешно справилось с прохождением baseline, а значит пора двигаться дальше - заняться оптимизацией модели, провести серию экспериментов и построить сильное финальное решения.\n",
    "\n",
    "В этом задании вам нужно провести ряд эскпериментов, оценить качество полученных в процессе экспериментирования моделей и выбрать лучшее решение. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание будет оцениваться на основании загруженного jupyther notebook и развернутых ответов на поставленные вопросы.\n",
    "\n",
    "## Загрузка библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix, hstack\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, f1_score, roc_auc_score, recall_score, precision_score, log_loss\n",
    "\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "seed = 1903\n",
    "first_categorial_index = 190"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объявим функции, необходимые для построения базовой модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_numericna(train_frame, test_frame, averageCalculator):\n",
    "    \"\"\" Функция заполняет значения в числовом фрейме значениями, посчитанными averageCalculator. \"\"\"\n",
    "    \n",
    "    # Посчитаем средние по колонкам\n",
    "    numeric_avgs = averageCalculator(train_frame)\n",
    "    \n",
    "    # Оставим только те колонки, в которых среднее значение не равно NaN, т.к. в таких колонках совсем нет значений\n",
    "    numeric_avgs = numeric_avgs.dropna()\n",
    "    dropped_columns = train_frame.columns.drop(numeric_avgs.index)\n",
    "    n_frame_train = train_frame[list(numeric_avgs.index)]\n",
    "    n_frame_test = test_frame[list(numeric_avgs.index)]\n",
    "    \n",
    "    # Заполним пропущенные численные значения средними\n",
    "    n_frame_train = n_frame_train.fillna(numeric_avgs, axis=0)\n",
    "    n_frame_test = n_frame_test.fillna(numeric_avgs, axis=0)\n",
    "    return (n_frame_train, n_frame_test, dropped_columns)\n",
    "\n",
    "def fill_numericna_means(train_frame, test_frame):\n",
    "    \"\"\" Функция заполняет значения в числовом фрейме средними и удаляет те колонки, в которых значений нет. \"\"\"\n",
    "    return fill_numericna(\n",
    "        train_frame,\n",
    "        test_frame,\n",
    "        lambda f: f.mean(axis=0, skipna=True))\n",
    "\n",
    "def remove_constant_features(frame, min_count=2):\n",
    "    \"\"\"Функция удаляет колонки, которые содержат только одно значение.\"\"\"\n",
    "    \n",
    "    # Посчитаем количества уникальных значений по колонкам\n",
    "    unique_counts = frame.nunique()\n",
    "    # Удалим колонки с количеством значений меньшим min_count\n",
    "    columns_to_drop = unique_counts[unique_counts < min_count].index\n",
    "    \n",
    "    return (frame.drop(columns=columns_to_drop), columns_to_drop)\n",
    "\n",
    "class MatrixLabelEncoder:\n",
    "    \"\"\" Класс кодирует категории числами от 0 до n, где n количество категорий в колонке. \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.encoders = []\n",
    "    \n",
    "    def fit(self, matrix):\n",
    "        for column_number in range(matrix.shape[1]):\n",
    "            column = matrix[:,column_number]\n",
    "            labelEncoder = LabelEncoder().fit(column)\n",
    "            self.encoders.append(labelEncoder)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, matrix):\n",
    "        transformed = np.empty(matrix.shape)\n",
    "        for column_number in range(matrix.shape[1]):\n",
    "            labelEncoder = self.encoders[column_number]\n",
    "            num_column = labelEncoder.transform(matrix[:,column_number])\n",
    "            for row_number, val in enumerate(num_column):\n",
    "                transformed[row_number, column_number] = val\n",
    "        return transformed\n",
    "    \n",
    "class CompositeEncoder:\n",
    "    \"\"\" Класс принимает набор фабрик с методами fit и transform и последовательно применяет их \"\"\"\n",
    "    def __init__(self, encoder_factories):\n",
    "        self.encoder_factories = encoder_factories\n",
    "        \n",
    "    def fit(self, matrix):\n",
    "        encoders = []\n",
    "        transformed = matrix\n",
    "        for encoder_factory in self.encoder_factories:\n",
    "            encoder = encoder_factory().fit(transformed)\n",
    "            encoders.append(encoder)\n",
    "            transformed = encoder.transform(transformed)\n",
    "        self.encoders = encoders\n",
    "        return self\n",
    "\n",
    "    def transform(self, matrix):\n",
    "        for encoder in self.encoders:\n",
    "            matrix = encoder.transform(matrix)\n",
    "        return matrix\n",
    "    \n",
    "def predict_ridge_proba(X, model):\n",
    "    \"\"\" Функция возвращает вероятности предсказаний для класса churn модель Ridge \"\"\"\n",
    "    # Поскольку RidgeClassifier не обладает функцией predict_proba приходится считать его вручную\n",
    "    # Подробнее можно посмотреть здесь:\n",
    "    # https://www.codesd.com/item/scikit-learn-ridge-classifier-extract-class-probabilities.html\n",
    "    func = model.decision_function(X)\n",
    "    return np.exp(func) / (1 + np.exp(func))\n",
    "\n",
    "def predict_model_proba(X, model):\n",
    "    \"\"\" Функция возвращает вероятности предсказаний для класса churn \"\"\"\n",
    "    return list(zip(*model.predict_proba(X)))[1]\n",
    "    \n",
    "def stratifiedKFold_fscore(\n",
    "    frame,\n",
    "    labels,\n",
    "    model_factory,\n",
    "    process_frame,\n",
    "    frame_to_matrix,\n",
    "    numeric_features,\n",
    "    categorial_features,\n",
    "    predict_probabilities,\n",
    "    seed,\n",
    "    folds_count = 3):\n",
    "    \"\"\" Функция разбивает набор данных на folds_count, считает ROC-AUC на каждом фолде\n",
    "        и возвращает усредненное по фолдам значение.\n",
    "        Функция также возвращает модель, показавшую лучшее качество, её метрики и разделение данных.\n",
    "        Разделение данных нужно для того, чтобы строить метрики модели на данных, на которых она не обучалась.\"\"\"\n",
    "    skf = StratifiedKFold(n_splits=folds_count, shuffle=True, random_state=seed)\n",
    "    \n",
    "    best_model = None\n",
    "    best_score = 0\n",
    "    best_precision = 0\n",
    "    best_recall = 0\n",
    "    best_table = None\n",
    "    best_split = None\n",
    "    best_encoders = None\n",
    "    best_dropped_columns = None\n",
    "    metrics_sum = 0\n",
    "    for train_indices, test_indices in skf.split(frame, labels):\n",
    "        # Разобьем фрем на train и test с помощью функции process_frame\n",
    "        # Внутри такой функции мы можем по-разному обрабатывать признаки обучаясь только на train наборе.\n",
    "        train_frame, train_labels, test_frame, test_labels, dropped_numeric, dropped_categorial = process_frame(\n",
    "            frame.loc[train_indices, :],\n",
    "            labels.loc[train_indices, :],\n",
    "            frame.loc[test_indices, :],\n",
    "            labels.loc[test_indices, :],\n",
    "            numeric_features,\n",
    "            categorial_features)\n",
    "        numeric_cleaned = numeric_features.drop(dropped_numeric)\n",
    "        categorial_cleaned = categorial_features.drop(dropped_categorial)\n",
    "        # Преобразуем фреймы в матрицы.\n",
    "        # Тут можно выполнить финальное преобразование признаков, например масштабирование признаков.\n",
    "        # В функции frame_to_matrix энкодеры типа StandardScaler обучаются только на train признаках.\n",
    "        X_train, X_test, num_encoder, cat_encoder = frame_to_matrix(\n",
    "            train_frame,\n",
    "            test_frame,\n",
    "            numeric_cleaned,\n",
    "            categorial_cleaned)\n",
    "        y_train = train_labels.as_matrix().flatten()\n",
    "        y_test = test_labels.as_matrix().flatten()\n",
    "\n",
    "        model = model_factory()\n",
    "        # Обучим модель\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Построим вероятности принадлежности к целевому классу\n",
    "        probabilities = predict_probabilities(X_test, model)\n",
    "        # Считаем roc auc score\n",
    "        rocAuc = roc_auc_score(y_test, probabilities)\n",
    "        metrics_sum += rocAuc\n",
    "        if(best_model is None or best_score < rocAuc):\n",
    "            # В случае, если модель лучше предыдущих сохраним её\n",
    "            # оценку, модель, матрицу ошибок и разделение данных\n",
    "            best_score = rocAuc\n",
    "            best_model = model\n",
    "            best_dropped_columns = (dropped_numeric, dropped_categorial)\n",
    "            best_encoders = (num_encoder, cat_encoder)\n",
    "            best_split = (X_train, y_train, X_test, y_test)\n",
    "    return (\n",
    "        metrics_sum/folds_count,\n",
    "        best_model,\n",
    "        best_score,\n",
    "        best_split,\n",
    "        best_encoders,\n",
    "        best_dropped_columns)\n",
    "\n",
    "def cleanup_frame_common(frame, numeric_features, categorial_features):\n",
    "    \"\"\"Функция делит признакина числовые и категориальные и удаляет константные признаки, содержащие только одно значение\"\"\"\n",
    "    # Разделим коллекции на группы - числовые и категориальные.\n",
    "    numeric_frame = frame[numeric_features].copy()\n",
    "    categorial_frame = frame[categorial_features].copy()\n",
    "    # Удалим вещественные колонки, содержащие одно и менее значений. 0 значений мы получаем, когда значения во всех строках Nan.\n",
    "    numeric_frame_no_const, dropped_const_numeric_columns = remove_constant_features(numeric_frame)\n",
    "    \n",
    "    # Удалим категориальные колонки, содержащие ноль значений. Если есть одно значение, то могут быть Nan, которые для\n",
    "    # категориальных признаков могут быть еще одной категорией (зависит от стратегии обработки).\n",
    "    categorial_frame_no_const, dropped_const_categorial_columns = remove_constant_features(categorial_frame, 1)\n",
    "    \n",
    "    # Восстановим фрейм и вернем вместе с ним список удаленных категориальных колонок.\n",
    "    return (pd.concat([numeric_frame, categorial_frame], axis=1),\n",
    "            list(dropped_const_numeric_columns),\n",
    "            list(dropped_const_categorial_columns))\n",
    "\n",
    "def process_frame_base_model(train_frame, train_labels, test_frame, test_labels, numeric_features, categorial_features):\n",
    "    \"\"\" Функция строит базовую модель из предыдущей недели \"\"\"\n",
    "    \n",
    "    # Удалим константные колонки из train_frame, и такие-же колонки из test_frame\n",
    "    train_frame, const_numeric_columns, const_categorial_columns = cleanup_frame_common(\n",
    "        train_frame,\n",
    "        numeric_features,\n",
    "        categorial_features)\n",
    "    test_frame = test_frame.drop(columns=const_numeric_columns)\n",
    "    test_frame = test_frame.drop(columns=const_categorial_columns)\n",
    "    \n",
    "    numeric_features = numeric_features.drop(const_numeric_columns)\n",
    "    categorial_features = categorial_features.drop(const_categorial_columns)\n",
    "    \n",
    "    # Заполним пропущенные вещественные значения средними\n",
    "    numeric_train, numeric_test, dropped_numeric = fill_numericna_means(\n",
    "        train_frame[numeric_features],\n",
    "        test_frame[numeric_features])\n",
    "    \n",
    "    numeric_features = numeric_features.drop(dropped_numeric)\n",
    "    \n",
    "    # Заполним пропущенные категориальные значения строками \"NaV\" (Not a value)\n",
    "    categorial_train = train_frame[categorial_features].fillna(\"NaV\")\n",
    "    categorial_test = test_frame[categorial_features].fillna(\"NaV\")\n",
    "    \n",
    "    # Удалим категориальные колонки с одним единственным значением\n",
    "    categorial_train, dropped_categorial = remove_constant_features(categorial_train)\n",
    "    categorial_test = categorial_test.drop(columns=dropped_categorial)\n",
    "    \n",
    "    categorial_features = categorial_features.drop(dropped_categorial)\n",
    "    \n",
    "    # Список удаленных колонок\n",
    "    dropped_numeric = np.concatenate([\n",
    "        list(const_numeric_columns),\n",
    "        list(dropped_numeric)])\n",
    "    dropped_categorial = np.concatenate([\n",
    "        list(const_categorial_columns),\n",
    "        list(dropped_categorial)])\n",
    "    \n",
    "    return (pd.concat([numeric_train, categorial_train], axis=1),\n",
    "            train_labels,\n",
    "            pd.concat([numeric_test, categorial_test], axis=1),\n",
    "            test_labels,\n",
    "            dropped_numeric,\n",
    "            dropped_categorial)\n",
    "\n",
    "def scale_features(train_frame, test_frame):\n",
    "    train_numeric = train_frame.as_matrix()\n",
    "    \n",
    "    scaler = StandardScaler().fit(train_numeric)\n",
    "    \n",
    "    train_numeric = coo_matrix(scaler.transform(train_numeric))\n",
    "    test_numeric = coo_matrix(scaler.transform(test_frame.as_matrix()))\n",
    "    \n",
    "    return (train_numeric, test_numeric, scaler)\n",
    "\n",
    "def one_hot_features(train_frame, test_frame):\n",
    "    fit_matrix = pd.concat([train_frame, test_frame]).as_matrix()\n",
    "    \n",
    "    if fit_matrix.shape[0] == 0 or fit_matrix.shape[1] == 0:\n",
    "        return (coo_matrix(train_frame.as_matrix()), coo_matrix(test_frame.as_matrix()), None)\n",
    "    categorial_encoder = CompositeEncoder([MatrixLabelEncoder, OneHotEncoder]).fit(fit_matrix)\n",
    "    \n",
    "    train_categorial = categorial_encoder.transform(train_frame.as_matrix())\n",
    "    test_categorial = categorial_encoder.transform(test_frame.as_matrix())\n",
    "    \n",
    "    return (train_categorial, test_categorial, categorial_encoder)\n",
    "\n",
    "def int_label_features(train_frame, test_frame):\n",
    "    fit_matrix = pd.concat([train_frame, test_frame]).as_matrix()\n",
    "    categorial_encoder = MatrixLabelEncoder().fit(fit_matrix)\n",
    "    \n",
    "    train_categorial = categorial_encoder.transform(train_frame.as_matrix())\n",
    "    test_categorial = categorial_encoder.transform(test_frame.as_matrix())\n",
    "    \n",
    "    return (train_categorial, test_categorial, categorial_encoder)\n",
    "\n",
    "def frame_to_matrix_one_hot(train_frame, test_frame, numeric_features, categorial_features):\n",
    "    \"\"\" Функци преобразует фрейм к sparse матрице.\n",
    "        Масштабирует вещественные признаки и кодирует категориальные с помощью OneHotEncoding. \"\"\"\n",
    "    \n",
    "    # Масштабируем вещественные признаки\n",
    "    train_numeric, test_numeric, scaler = scale_features(\n",
    "        train_frame[numeric_features],\n",
    "        test_frame[numeric_features])\n",
    "    \n",
    "    # Закодируем категориальные признаки значениями от 0 до n с помощью MatrixLabelEncoder\n",
    "    # One hot encode для категориальных признаков\n",
    "    train_categorial, test_categorial, categorial_encoder = one_hot_features(\n",
    "        train_frame[categorial_features],\n",
    "        test_frame[categorial_features])\n",
    "    \n",
    "    return (hstack([train_numeric, train_categorial]),\n",
    "            hstack([test_numeric, test_categorial]),\n",
    "            scaler,\n",
    "            categorial_encoder)\n",
    "\n",
    "def frame_to_matrix_labeled(train_frame, test_frame, numeric_features, categorial_features):\n",
    "    \"\"\" Функция преобразует фрейм к sparse матрице.\n",
    "        Масштабирует вещественные признаки и кодирует категориальные целыми числами. \"\"\"\n",
    "    \n",
    "    # Масштабируем вещественные признаки\n",
    "    train_numeric, test_numeric, scaler = scale_features(\n",
    "        train_frame[numeric_features],\n",
    "        test_frame[numeric_features])\n",
    "    \n",
    "    # Закодируем категориальные признаки значениями от 0 до n с помощью MatrixLabelEncoder\n",
    "    train_categorial, test_categorial, categorial_encoder = int_label_features(\n",
    "        train_frame[categorial_features],\n",
    "        test_frame[categorial_features])\n",
    "    \n",
    "    return (hstack([train_numeric, train_categorial]),\n",
    "            hstack([test_numeric, test_categorial]),\n",
    "            scaler,\n",
    "            categorial_encoder)\n",
    "\n",
    "def ridge_baseline_builder(frame, labels, numeric_features, categorial_features):\n",
    "    return stratifiedKFold_fscore(\n",
    "        frame,\n",
    "        labels,\n",
    "        RidgeClassifier,\n",
    "        process_frame_base_model,\n",
    "        frame_to_matrix_one_hot,\n",
    "        numeric_features,\n",
    "        categorial_features,\n",
    "        predict_ridge_proba,\n",
    "        seed)\n",
    "\n",
    "def random_forest_baseline_builder(frame, labels, numeric_features, categorial_features):\n",
    "    return stratifiedKFold_fscore(\n",
    "        frame,\n",
    "        labels,\n",
    "        RandomForestClassifier,\n",
    "        process_frame_base_model,\n",
    "        frame_to_matrix_labeled,\n",
    "        numeric_features,\n",
    "        categorial_features,\n",
    "        predict_model_proba,\n",
    "        seed)\n",
    "\n",
    "def gradient_boosting_baseline_builder(frame, labels, numeric_features, categorial_features):\n",
    "    return stratifiedKFold_fscore(\n",
    "        frame,\n",
    "        labels,\n",
    "        GradientBoostingClassifier,\n",
    "        process_frame_base_model,\n",
    "        frame_to_matrix_labeled,\n",
    "        numeric_features,\n",
    "        categorial_features,\n",
    "        predict_model_proba,\n",
    "        seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27999, 230)\n",
      "(27999, 1)\n"
     ]
    }
   ],
   "source": [
    "churn_data_frame = pd.read_csv(\"..\\..\\Data\\churn_data_train.csv\", \",\", dtype= { \"Var73\": np.float64 })\n",
    "churn_labels_frame = pd.read_csv(\"..\\..\\Data\\churn_labels_train.csv\", dtype= { \"labels\": np.int64 })\n",
    "print(churn_data_frame.shape)\n",
    "print(churn_labels_frame.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделим числовые и категориальные признаки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = churn_data_frame.columns[:first_categorial_index]\n",
    "categorial_columns = churn_data_frame.columns[first_categorial_index:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Базовые модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_base = ridge_baseline_builder(\n",
    "    churn_data_frame,\n",
    "    churn_labels_frame,\n",
    "    numeric_columns,\n",
    "    categorial_columns)\n",
    "random_forest_base = random_forest_baseline_builder(\n",
    "    churn_data_frame,\n",
    "    churn_labels_frame,\n",
    "    numeric_columns,\n",
    "    categorial_columns)\n",
    "gradient_boosting_base = gradient_boosting_baseline_builder(\n",
    "    churn_data_frame,\n",
    "    churn_labels_frame,\n",
    "    numeric_columns,\n",
    "    categorial_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На 2-й неделе я выбрал в качестве основной метрики F-Score, после 4-й неделе я решил изменить метрику. В качестве основной метрики я буду использовать ROC-AUC. Причина проста. Я максимизирую площадь под ROC кривой, а потом с помощью того-же F-Score могу подобрать оптимальный порог, чтобы максимизировать качество предсказаний.\n",
    "\n",
    "## Инструкции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Начнем с простого. Давайте оценим как много объектов действительно нужно для построения качественной модели. Для обучения доступна достаточно большая выборка и может так оказаться, что начиная с некоторого момента рост размера обучающей выборки перестает влиять на качество модели. Постройте кривые обучения, обучая модель на выборках разного размера начиная с небольшого количество объектов в обучающей выборке и постепенно наращивая её размер с некоторым шагом. Обратите внимание на `sklearn.model_selection.learning_curve`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_frame_size(\n",
    "    pinned_data,\n",
    "    data,\n",
    "    best_metric,\n",
    "    best_size,\n",
    "    round_size=5):\n",
    "    step_metric = best_metric\n",
    "    step_frame, step_labels = data\n",
    "    step_indices = None\n",
    "    left_frame = None\n",
    "    better_metric = best_metric\n",
    "    better_size = best_size\n",
    "    \n",
    "    while step_metric >= best_metric:\n",
    "        skf = StratifiedKFold(\n",
    "            n_splits=2,\n",
    "            shuffle=True,\n",
    "            random_state=seed)\n",
    "        step_indices = list(skf.split(step_frame, step_labels))[0][0]\n",
    "        if(len(step_indices) < 14):\n",
    "            break\n",
    "        left_frame = step_frame.drop(step_indices).reset_index(drop=True)\n",
    "        left_labels = step_labels.drop(step_indices).reset_index(drop=True)\n",
    "        step_frame = step_frame.loc[step_indices, :].reset_index(drop=True)\n",
    "        step_labels = step_labels.loc[step_indices, :].reset_index(drop=True)\n",
    "        \n",
    "        pinned_frame,pinned_labels = pinned_data\n",
    "        step_frame = pd.concat([pinned_frame, step_frame], axis=0, ignore_index=True)\n",
    "        step_labels = pd.concat([pinned_labels, step_labels], axis=0, ignore_index=True).astype(np.int64)\n",
    "        step_model = gradient_boosting_baseline_builder(\n",
    "            step_frame,\n",
    "            step_labels,\n",
    "            numeric_columns,\n",
    "            categorial_columns)\n",
    "        step_metric = np.round(step_model[0], round_size)\n",
    "        if(step_metric >= better_metric):\n",
    "            better_metric = step_metric\n",
    "            better_size = step_frame.shape\n",
    "        print (\"Frame_size %i: %.5f\\tInitial quality: %.5f\\tLeft_size\" % (step_frame.shape[0], step_metric, best_metric, left_frame.shape[0]))\n",
    "    \n",
    "    if(len(step_indices) < 14):\n",
    "        return (better_metric, better_size)\n",
    "    else:\n",
    "        return find_best_frame_size(\n",
    "            (step_frame, step_labels),\n",
    "            (left_frame, left_labels),\n",
    "            better_metric,\n",
    "            better_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame\n",
      "Labels\n",
      "labels int64 int64\n"
     ]
    }
   ],
   "source": [
    "p_f,p_l = (pd.DataFrame([], columns=churn_data_frame.columns), pd.DataFrame([], columns=churn_labels_frame.columns, dtype=np.int64))\n",
    "f,l = (churn_data_frame, churn_labels_frame)\n",
    "s_f = pd.concat([p_f, f], axis=0, ignore_index=True).reset_index(drop=True)\n",
    "s_l = pd.concat([p_l, l], axis=0, ignore_index=True).reset_index(drop=True).astype(np.int64)\n",
    "\n",
    "print(\"Frame\")\n",
    "for col in s_f.columns:\n",
    "    if(s_f[col].dtype != churn_data_frame[col].dtype):\n",
    "        print (col, s_f[col].dtype, churn_data_frame[col].dtype)\n",
    "print(\"Labels\")\n",
    "for col in s_l.columns:\n",
    "    print (col, s_l[col].dtype, churn_labels_frame[col].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame_size 13999: 0.71973\tInitial quality: 0.73193\n",
      "Frame_size 20999: 0.71970\tInitial quality: 0.73193\n",
      "Frame_size 24498: 0.73466\tInitial quality: 0.73193\n",
      "Frame_size 33248: 0.75575\tInitial quality: 0.73193\n",
      "Frame_size 37622: 0.77225\tInitial quality: 0.73193\n",
      "Frame_size 39810: 0.77649\tInitial quality: 0.73193\n",
      "Frame_size 40903: 0.78120\tInitial quality: 0.73193\n",
      "Frame_size 41450: 0.78414\tInitial quality: 0.73193\n",
      "Frame_size 41723: 0.78399\tInitial quality: 0.73193\n",
      "Frame_size 41860: 0.78850\tInitial quality: 0.73193\n"
     ]
    }
   ],
   "source": [
    "find_best_frame_size(\n",
    "    (pd.DataFrame([], columns=churn_data_frame.columns), pd.DataFrame([], columns=churn_labels_frame.columns)),\n",
    "    (churn_data_frame, churn_labels_frame),\n",
    "    np.round(gradient_boosting_base[0], 5),\n",
    "    churn_data_frame.shape)\n",
    "\n",
    "# Substitute stratified k-fold, to another split logic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Часто несбалансированные по классам выборки приводят к различным проблемам при обучении моделей. Давайте попробуем по-разному обработать выборку, поиграть с распределением объектов по классам и сделать выводы о том, как соотношение классов влияет на качество модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1\\. Задайте веса объектам так, чтобы соотношение классов с учетом весов объектов изменилось. Попробуйте не менее трёх различных вариантов весов. Меняются ли результаты классификации? Как это сказывается на качестве модели? Какой вариант выглядит наиболее оптимальным с точки зрения качества?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2\\. Примените к выборке технологию undersampling: для этого нужно убрать из обучения некоторое количество объектов большего класса таким образом, чтобы соотношение классов изменилось. Попробуйте не менее трёх различных вариантов undersampling (варианты могут отличаться как по количество отфильтрованных объектов, так и по принципу выборка объектов для отсеивания из выборки). Меняются ли результаты классификации? Как это сказывается на качестве модели? Какой вариант выглядит наиболее оптимальным с точки зрения качества?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Теперь перейдем к работе с признаками. Ранее вы реализовали несколько стратегий для обработки пропущенных значений. Сравните эти стратегии между собой с помощью оценки качества моделей кросс-валидации, построенных на датасетах с использованием различных стратегий. Как обработка пропущенных значений сказывается на качестве модели? Какой вариант выглядит наиболее оптимальным с точки зрения качества?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Также вы уже реализовали несколько стратегий для обработки категориальных признаков. Сравните эти стратегии между собой с помощью оценки качества моделей по кросс-валидации, построенных на датасетах с использованием различных стратегий. Как обработка категориальных признаков сказывается на качестве модели? Какой вариант выглядит наиболее оптимальным с точки зрения качества?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. Все ли признаки оказались полезными для построения моделей? Проведите процедуру отбора признаков, попробуйте разные варианты отбора (обратите внимание на модуль `sklearn.feature_selection`). Например, можно выбрасывать случайные признаки или строить отбор на основе l1-регуляризации - отфильтровать из обучения признаки, которые получат нулевой вес при построении регрессии с l1-регуляризацией (`sklearn.linear_model.Lasso`). И всегда можно придумать что-то своё=) Попробуйте как минимум 2 различные стратегии, сравните результаты. Помог ли отбор признаков улучшить качество модели? Поясните свой ответ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Подберите оптимальные параметры модели. Обратите внимание, что в зависимости от того, как вы обработали исходные данные, сделали ли балансировку классов, сколько объектов оставили в обучающей выборке и др. оптимальные значения параметров могут меняться. Возьмите наилучшее из ваших решений на текущий момент и проведите процедуру подбора параметров модели (обратите внимание на `sklearn.model_selection.GridSearchCV`) Как подбор параметров повлиял на качество модели?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7\\. Предложите методику оценки того, какие признаки внесли наибольший вклад в модель (например, это могут быть веса в случае регрессии, а также большое количество моделей реализуют метод `feature_importances_` - оценка важности признаков). На основе предложенной методики проанализируйте, какие признаки внесли больший вклад в модель, а какие меньший?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8\\. Напоследок давайте посмотрим на объекты. На каких объектах достигается наибольшая ошибка классификации? Есть ли межу этими объектами что-то общее? Видны ли какие-либо закономерности? Предположите, почему наибольшая ошибка достигается именно на этих объектах. В данном случае \"наибольшую\" ошибку можно понимать как отнесение объекта с чужому классу с большой долей уверенности (с высокой вероятностью)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9\\. По итогам проведенных экспериментов постройте финальную решение - модель с наилучшим качеством. Укажите, какие преобразования данных, параметры и пр. вы выбрали для построения финальной модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10\\. Подумайте, можно ли еще улучшить модель? Что для этого можно сделать? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
