{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Построение и оптимизация модели\n",
    "\n",
    "В этом задании вам предстоит поучаствовать в соревновании на [kaggle inclass](https://inclass.kaggle.com/c/telecom-clients-churn-prediction).\n",
    "В соревновании вы будете работать с той же выборкой, что и ранее, поэтому воспользуйтесь результатами, полученными на предыдущих неделях. Для успешного участия в соревновании необходимо преодолеть по качеству beseline решение.\n",
    "\n",
    "Итак, мы научились обрабатывать данные, выбрали схему кросс-валидации и определились с метриками качества. Пора переходить к оптимизации модели. На этой неделе вам предстоит принять участие в соревновании на платформе kaggle inclass! Цель такого соревнования - преодолеть предложенное baseline решение, а, главное, обсудить и сравнить предложенные решения на форуме. Какие признаки оказали наибольший вклад в модель? Как лучше обрабатывать категориальные признаки? Нужно ли делать отбор признаков, А балансировать выборку? Экспериментируйте с данными и обсуждайте ваши решения на форуме!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix, hstack\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, f1_score, roc_auc_score, recall_score, precision_score, log_loss\n",
    "\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "seed = 1903\n",
    "first_categorial_index = 190"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27999, 230)\n",
      "(27999, 1)\n"
     ]
    }
   ],
   "source": [
    "churn_data_frame = pd.read_csv(\"..\\..\\Data\\churn_data_train.csv\", \",\")\n",
    "churn_labels_frame = pd.read_csv(\"..\\..\\Data\\churn_labels_train.csv\")\n",
    "print(churn_data_frame.shape)\n",
    "print(churn_labels_frame.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Общая предобработка признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_frame(frame):\n",
    "    \"\"\"Функция масштабирает frame на отрезок [0;1]\"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    scaled_matrix = scaler.fit_transform(frame.as_matrix())\n",
    "    return pd.DataFrame(scaled_matrix, columns=frame.columns)\n",
    "\n",
    "def fill_numericna_means(frame):\n",
    "    \"\"\" Функция заполняет значения в числовом фрейме средними и удаляет те колонке, в которых значений нет. \"\"\"\n",
    "    n_frame = frame\n",
    "    \n",
    "    # Посчитаем средние по колонкам\n",
    "    numeric_means = n_frame.mean(axis=0, skipna=True)\n",
    "    # Оставим только те колонки, в которых среднее значение не равно NaN, т.к. в таких колонках совсем нет значений\n",
    "    numeric_means = numeric_means.dropna()\n",
    "    dropped_columns = n_frame.columns.drop(numeric_means.index)\n",
    "    n_frame = n_frame[list(numeric_means.index)]\n",
    "    # Заполним пропущенные численные значения средними\n",
    "    n_frame = n_frame.fillna(numeric_means, axis=0)\n",
    "    return (n_frame, dropped_columns)\n",
    "    \n",
    "def remove_constant_features(frame):\n",
    "    \"\"\"Функция удаляет колонки, которые содержат только одно значение.\"\"\"\n",
    "    \n",
    "    # Посчитаем количества уникальных значений по колонкам\n",
    "    unique_counts = frame.nunique()\n",
    "    # Удалим колонки с одним уникальным значением\n",
    "    columns_to_drop = unique_counts[unique_counts <= 1].index\n",
    "    \n",
    "    return (frame.drop(columns=columns_to_drop), columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим коллекции на группы - числовые и категориальные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = churn_data_frame.columns[:first_categorial_index]\n",
    "categorial_columns = churn_data_frame.columns[first_categorial_index:]\n",
    "\n",
    "numeric_frame = churn_data_frame[numeric_columns].copy()\n",
    "categorial_frame = churn_data_frame[categorial_columns].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалим вещественные колонки, содержащие одно и менее значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_frame_no_const, dropped_const_numeric_columns = remove_constant_features(numeric_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполним пропущенные вещественные значения средними"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_frame_means, dropped_na_numeric_columns = fill_numericna_means(numeric_frame_no_const)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполним пропущенные категориальные значения строками \"NaV\" (Not a value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorial_frame_nav = categorial_frame.fillna(\"NaV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалим категориальные колонки с одним единственным значением"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorial_frame_nav_no_const, dropped_categorial_columns = remove_constant_features(categorial_frame_nav)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Список удаленных колонок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Var8, Var15, Var20, Var31, Var32, Var39, Var42, Var48, Var52, Var55, Var79, Var118, Var141, Var167, Var169, Var175, Var185, Var209, Var230\n"
     ]
    }
   ],
   "source": [
    "dropped_columns = np.concatenate([\n",
    "        list(dropped_const_numeric_columns),\n",
    "        list(dropped_na_numeric_columns),\n",
    "        list(dropped_categorial_columns)])\n",
    "print (\", \".join(dropped_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заполнить пропущенные вещественные значения медианами\n",
    "# Заполнить пропущенные категориальные значения самой частой категорией\n",
    "# Масштабировать\n",
    "# Oversampling/Undersampling/No sampling\n",
    "# Удалить признаки не коррелирующие с целевой переменной или добавлять по одному признаку по убыванию корреляции,\n",
    "#   пока растет качество.\n",
    "# Удалить признаки сильно коррелирующие друг с другом или удалять по одному, пока растет качество.\n",
    "# Автоматический отсев признаков\n",
    "\n",
    "# Для линейной модели попробовать бинаризацию вместо OneHot\n",
    "# Для остальных попробовать бинаризацию вместо Labeled\n",
    "# Попробовать другие способы работы с категориальными признаками\n",
    "\n",
    "# Поискать скоррелированные значения между категориальными и численными признаками"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
